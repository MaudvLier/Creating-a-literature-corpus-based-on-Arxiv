I


Tremendous progress in both machine learning and computational
neuroscience is leading to the development of neural processing
algorithms that have far reaching impact on our daily lives *REF* 
These neural network algorithms can perform remarkable learning and
pattern recognition tasks that in some cases even outperform humans.
However, they are typically run on conventional computing systems
based on the von Neumann architecture and are commonly
implemented using large and power-hungry platforms, sometimes
distributed across multiple machines in server farms. The power
required to run these algorithms and achieve impressive results is
orders of magnitude larger than the one used by biological nervous
systems and is not sustainable for the future needs of ubiquitous
computing at scale. The reasons for the large gap in energy costs
between artificial and natural neural processing systems are still
being investigated, however it is clear that one fundamental diﬀerence
lies in the way the elementary computing processes are organized:
conventional computers use Boolean logic, bit-precise digital
representations, time-multiplexed and clocked operations; nervous
systems, on the other hand, carry out robust and reliable computation
using analog components that are inherently noisy and operate in
continuous time and activation domains. These components typically
communicate among each other with all-or-none discrete events
(spikes), thus using a combination of analog computation and digital
communication. Moreover, they form distributed, event-driven, and
massively parallel systems; and they feature considerable amount of
adaptation, self-organization, and learning with dynamics that operate
on a multitude of time-scales.


One promising approach for bridging this gap is to develop a new
generation of ultra-low power and massively parallel computing technologies, optimally suited to
implementing neural network architectures that use the same spatial
and temporal principles of computation used by the brain. This
&quot;neuromorphic engineering&quot; approach *REF* is the same one that was
originally proposed in the early &apos;90s *REF* but which is starting to
show its full potential only now. Neuromorphic circuits are typically
designed using analog, digital, or mixed-mode analog/digital
Complementary Metal-Oxide-Semiconductor (CMOS) transistors, and are
well suited for exploiting the features of emerging memory
technologies and new memristive materials *REF*. Similar to the
biological systems they model, neuromorphic systems process
information using energy-eﬃcient asynchronous, event-driven methods
*REF*; they are often adaptive, fault-tolerant, and can be flexibly
configured to display complex behaviors by combining multiple
instances of simpler elements. Remarkable neuromorphic computing
platforms have been developed in the past for modeling cortical
circuits, solving pattern recognition problems, and implementing
machine learning tasks *REF* or for accelerating the simulation of
computational neuroscience models *REF*. In parallel, impressive
full-custom dedicated accelerators have been proposed for implementing
convolutional and deep network algorithms following the more
conventional digital design flow *REF*. While these systems
significantly reduce the power consumption in a wide variety of neural
network applications, compared to conventional computing approaches,
they still fall short of reproducing the power, size, and adaptivity
of biological neural processing systems.


Indeed, developing low power, compact, and autonomous electronic
&quot;agents&quot; that can interact with the environment to extract relevant
information from the signals they sense in real-time, adapt to the
changes and uncertain conditions present in both the external inputs
and internal states, and that can learn to produce context dependent
behaviors for carrying out goal-directed procedural tasks, is still an
open challenge.


To address this challenge and find an optimal computational substrate
that minimizes size and power consumption for systems that generate
behavior in real world, we argue, the computing principles that
underlie autonomous adaptive behavior need to be matched by the
computing hardware in which computation is realized. In particular, in
order to fully benefit from the emulation of biological neural
processing systems, it is important to preserve two of their
fundamental characteristics: the explicit representation of time and
the explicit use of space. In the following, we will first present the
design principles for building neuromorphic electronic systems that
make use of these representations, and then show how such explicit
representation of time and space matches a computing framework of
dynamic neural fields that embodies principles of autonomous behavior
generation and learning *REF*. Finally, we demonstrate successful
realizations of autonomous neural-dynamic architectures in
neuromorphic hardware, emphasizing the role of explicit time and space
representation in hardware for eﬃciency of the autonomous neuronal
controllers.


D 


A. Physical space in hardware neural processing systems


In an eﬀort to minimize silicon area consumption, digital neuromorphic
processors typically use time-multiplexing techniques to share
circuits which simulate neural dynamics for modeling multiple neurons
*REF*. This requires that the shared circuits continuously
transfer their state variables to and from an external memory block at
each update cycle (therefore burning extra power for the data
transfer). The faster the transfer and cycle rate, the larger number
of neurons can be simulated per time unit. In addition, if these
circuits need to model processes that evolve continuously over natural
time, such as the leak term of a leaky integrate and fire (I&amp;F) neuron
model, then it is necessary to include a clock to update the related
state variables periodically and manage the passing of time (thus
adding extra overhead and power consumption).


Unlike digital simulators of neural networks, analog neuromorphic
circuits use the physics of silicon to directly emulate neural and
synaptic dynamics *REF*. In this case the state variables
evolve naturally over time and &quot;time represents itself&quot; *REF*,
bypassing the need to have clocks and extra circuits to manage the
representation of time. Furthermore, since the state variable memory
is held in the synapse and neuron capacitors there is no need to
transfer data to extra memory blocks, dramatically saving energy that
would otherwise be required to transfer the neuron state-variables
back and forth from memory. Examples of neuromorphic architectures
that follow this mixed-signal approach include the Italian ISS
recurrent network with plasticity and long-term memory chip *REF*, the
ISS &quot;final learning attractor neural network&quot; (FLANN) chip *REF*, the
Georgiatech Learning-Enabled Neuron Array IC *REF*, the UCSD
integrate-and-fire array transceiver (IFAT) architecture *REF*, the
US Stanford Neurogrid system *REF*, the Zurich INI dynamic
neuromorphic asynchronous processor chip *REF*, and the Zurich INI
recurrent on-line learning ROLLS neuromorphic processor *REF*.


In these devices the analog synapse and neuron circuits have no active
components *REF*. The circuits are driven directly by the input
&quot;streaming&quot; data. Their synapses receive input spikes and their
neurons produce output spikes, at the rate of the incoming data. So if
they are not processing data, there is no energy dissipated per
synaptic operation (SOP) and no dynamic power consumption. Therefore,
this approach is particularly attractive in the case of applications
in which the signals have sparse activity in space and time. Under
these conditions most neurons would be silent at any one time, thus
bringing the system power consumption to the minimum. A quantitative
comparison of the specification of these devices is presented in Table
I. The spike-based learning algorithms that some of these devices
implement are either based on the basic version of Spike-Timing
Dependent Plasticity (STDP) *REF*, or on more elaborate Spike-Timing
and Rate Dependent Plasticity (STRDP) *REF*.


While this approach is very power eﬃcient, it requires to instantiate
and place a distinct physical neuromorphic circuit per emulated
synapse or neuron, therefore needing an amount of physical area that
scales with the number of neurons in the network. This was a serious
limiting factor with older VLSI fabrication processes. However,
technology scaling pushed by Moore&apos;s law and the emergence of novel
nano-scale memory devices technologies that can be used to implement
both synaptic and neural dynamics *REF* brings renewed interest to
this approach and makes it very competitive compared to the classical
one of resorting to more compact digital designs based on shared
time-multiplexed circuits, as was done, e.g., for the IBM TrueNorth
*REF* and Intel Loihi *REF* neuromorphic processors.


TABLE


B. Natural time in hardware neural processing systems


For the approach based on parallel instances of mixed analog/digital
circuits as described above, the most power eﬃcient way of processing
time varying signals is to use circuit time constants that are well
matched to those of the dynamics of the signals that need to be
processed. For example, real-world &quot;natural&quot; events and signals such
as speech, bio-signals measured from the body, human gestures, or
motor and sensory signals measured from roving robots, would require
the synapse and neural circuits to have time constants in the range of
5 ms to 500 ms. It is important to realize that although the speed of
the individual synapse or neuron computing elements in such
architectures can be set to be relatively slow (e.g., compared to
digital circuits), the response time of the overall system can be
extremely fast. This is due to the fact that the many parallel
processing nodes in the system will be aﬀected by device mismatch and
have diﬀerent initial conditions; so upon the arrival of an external
input there will be many neurons very close to their firing threshold,
and they will produce an output with a latency that is much shorter
than their natural integration time-constant.


The relatively long time constants required by this approach are not
easy to realize using analog CMOS technology. Standard analog circuit
design techniques either lead to bulky and silicon-area expensive
solutions or fail to meet this condition, resorting to modeling neural
dynamics at accelerated time-scales *REF*. One elegant solution to
this problem is to combine the use of subthreshold circuit design
techniques *REF* with current-mode design one *REF*. A very compact
subthreshold log-domain circuit that can reproduce biologically
plausible synapticand neural temporal dynamics and that has been used in a wide variety
of neuromorphic applications *REF* is the Diﬀerential Pair
Integrator (DPI) circuit *REF*, depicted in Fig. 1. The analytic
transfer function of this circuit can be derived following a
translinear-loop log-domain analysis *REF*: From Fig. 1b it
follows that FORMULA where Iout represents the synaptic or neuron dynamic variable,
Iin the input signal, I⌧ a user defined leakage current, and
Ig a global gain term useful e.g. for modeling spike-based
learning, intrinsic plasticity, or synaptic scaling. This is a
non-linear diﬀerential equation. However, under the reasonable
assumptions of non-negligible input currents, such that Iin »
I⌧, and observing that for such condition the output current
Iout will eventually grow to be Iout » Ig, then this
equation simplifies to: FORMULA.


FIGURE



The circuit time constant is defined ad ⌧, CUT/I⌧. Long time
constants are achieved by using a combination of large capacitors and
small currents. Even though it is possible to implement such long time
constants without sacrificing large amounts of silicon real-estate
area, e.g., using high-k materials, memristive devices, or active
circuits that minimize leakage currents *REF*, there is a limit to
the maximum time constants that can be implemented at the level of the
single neural or synaptic components, and to the temporal scales that
they can deal with for processing slow changing signals. This is a
problem that also biological neural processing systems face, and
which can be solved by using network dynamics to model attractors and
long-term memory phenomena.


C. Extending neuronal dynamics to behavioral time scales using
attractor networks


Biological nervous systems are capable of controlling behavior and
processing sensory inputs in an adaptive and robust manner over a
multitude of time scales that extend well beyond those of the single
synapse and neuron time constants *REF*. Indeed in such systems there
are a multitude of neural circuits and mechanisms that underlie the
ability to process and generate temporal patterns over behavioral
time-scales *REF*. A common circuit motive found throughout multiple
parts of the cortex that is believed to sub-serve these functions is
the &quot;winner-take-all&quot; (WTA) network *REF*, which is a specific
type of attractor network *REF*. Theoretical studies have shown that
such networks provide elementary units of computation that can
stabilize and de-noise the neuronal dynamics *REF*. These
theoretical considerations have also been validated in neuromorphic
hardware systems to generate robust behavior in closed sensorimotor
loops *REF*. However, to extend these models and hardware neural
processing circuits to more complex systems, such as autonomous agents
that can make decisions and generate goal-directed behavior, it is
necessary to develop higher-level control strategies and theoretical
frameworks compatible with mixed signal neuromorphic hardware and
endowing neuromorophic architectures with compositionality and
modularity. The core challenge is to design neuronal networks for
neuromorphic hardware that can create and stabilize a neuronal state
that can drive movements of an autonomous agent that unfold at
arbitrary time-scales.


Recurrent networks of neural populations can indeed create sustained
activation to keep a neuronal state active for macroscopic, behavioral time intervals.
Such sustained neuronal states do not have to be static, but need to
create an invariant projection in the task-related subspace *REF*,
creating an attractor in this subspace that corresponds to the desired
value (i.e., a working memory state *REF*). These attractor-based
representations can sustain a variable duration of actions and
perceptual states and help to bridge the neuronal and behavioral time
scales in a robust way *REF*. For example, a recurrent neural
network dynamics that can be used for this purpose is described by the
following equation *REF*: FORMULA. (3) Here, u(x,t) is a neuronal 
activation function defined over a perceptual ormotor space x
that is encoded by a neuronal population. Such dimension, x, could
represent a continuous sensory feature such as color or orientation of a visual stimulus, or
a motor variable such as the hand position or orientation in space.
The term h in Eq. (3) is a negative resting level of the neuronal
population; the term I(x, t) is an external input, and f (·)
is a sigmoid non-linearity that smoothly filters population activity.
The last, integral term in the equation expresses the lateral
connectivity in the neuronal population with activity described by the
activation function u(x, t). In particular, the integral is a
convolution shaped by the interaction kernel w(\|x - x0\|) that
only depends on the distance between two positions. The interaction
kernel has a &quot;Mexican hat&quot; form of the type: FORMULA
where Aexc/inh and aexc/inh are the amplitude and spread
of the excitatory and inhibitory parts of the kernel. Such &quot;Mexican
hat&quot; pattern of lateral connections creates a soft WTA dynamics in the
neuronal population: the neurons that get activated first, if they are
supported by neighbouring (in the behavioral space) neurons, stay
activated and inhibit other neurons in the population. This
formalization of the dynamics of recurrent neural populations is known
as a Dynamic Neural Field (DNF) *REF*. Over decades, DNF theory
was developed into a framework for neuronal basis of cognition *REF* 
that has been recently applied to the control of cognitive robotic
agents *REF*.


The Dynamic Neural Field dynamics described by Eq. (3) can be
implemented as a WTA network in neuromorphic hardware. Figure 2a shows
such a scheme of a WTA / DNF implementation with spiking neurons.
Here, red circles designate neurons, a larger number of which form an
excitatory pool that represents the behavioral variable; the smaller
pool of neurons forms an inhibitory group that realises the inhibitory
part of interaction kernel in Eq. (3). Red lines are excitatory and
blue lines are inhibitory connections (shown for one of the inhibitory
neurons each).


The stable attractors created by such WTA dynamics are critical to
enable behavior learning in a closed sensory-motor loop in which the
sensory input changes continually as the agent generates action. In
order to learn a mapping between a sensory state and its consequences,
or a precondition and an action, the sensory state before the action
needs to be stored in a neuronal representation. This can be achieved
by creating a reverberating activation in a neuronal population that
can be sustained for the duration of the action and can be used to
update the sensorimotor mapping when a rewarding or punishing signal
is obtained *REF*.


FIGURE


D. Implementing on-chip learning in neuromorphic processors


Learning is probably the most important aspect of neural processing
systems: it allows them to be trained to form memories, create
associations, perform pattern classification or pattern recognition
tasks; most importantly, it endows autonomous agents with plasticity
features which enable them to adapt to changes in the statistics of
the input signals, or changes in the properties of their actuators
over long time scales.


FIGURE


In artificial neural processing systems learning typically involves
the update of synaptic weight values. This can require significant
amounts of extra resources in time-multiplexed systems, typically in
the form of state memory, memory-transfer bandwidth, and power,
especially if the storage is done using memory banks that are not on
the processor die (e.g., DRAM in large-scale systems). On the other
hand, the overhead needed to implement learning in mixedsignal
neuromorphic architectures that place multiple instances of synaptic
circuits per emulated synapse is very small. For example, Fig. 3, depicting the chip
micrograph of the ROLLS device *REF*, shows how the synapses that
comprise learning algorithms (denoted as LTP synapses) occupy
approximately the same area of the non-plastic synapses that have
fixed programmable weights and short-term plasticity dynamics (denoted
as STP synapses). Since each of these synapse circuits can be
stimulated individually by the chip input spikes, they can all operate
in parallel using slow dynamics (e.g., driven by pico-Ampere
currents), without having to transfer state memory at high speeds to
external memory banks. Here, the area used by the parallel circuits
allows to save bandwidth and power in implementing neural dynamics.
Furthermore, the feature of implementing biologically plausible time
constants and making use of explicit natural time scales, allows to
use the fast digital asynchronous Address-Event Representation (AER)
*REF* circuits for stimulating multiple synapses in parallel.


In our work, we used the ROLLS device of Fig. 3 to enable learning in
WTA networks to implement a hardware model of sequence learning
*REF*, as well as learning maps *REF* and sensorimotor mappings
*REF* in neuromorphic agents. Specifically, we used interconnected
populations of spiking neurons in a Winner-Take-All (WTA) fashion,
creating excitatory recurrent connections between neurons that encode similar features. When a group
of such interconnected neurons is activated, the excitatory
connections create an activation flow between neurons that can sustain
itself even after the initiating input yields. Such sustained
activation (or attractor) can drive down-stream structures, resulting
in a movement of the agent; the time structure of this movement can be
decoupled from the dynamics and timing of sensory input. Moreover,
learning between sustained attractor states can be triggered when a
rewarding or error signal is perceived.


The rather dense WTA connectivity requires parallel processing to be
eﬃciently computed. Moreover, non-linearities of the DNF dynamics --
which are crucial for its attractor properties -- need to be processed
for a large number of neurons in parallel. The explicit representation
of space in neuromorphic devices, such as the one of Fig. 3, leads to
a more eﬃcient implementation of the neuronal attractor network,
compared to hardware with time-multiplexing and virtual time. We thus
argue that neuromorphic devices that feature real-time processing with
timescales matching the task and with massively parallel network of
analog computing elements, when matched with a neuronal architecture
of attractor-based population dynamics can lead to eﬃcient
implementations of neuromorphic systems capable to generate cognitive
behavior. In the following Sections we present representative examples
of such neuromorphic agents.


N 


In this section, we describe neuronal architectures that make use of
the properties of neuromorphic devices with explicit representation
of neuronal substrate and real time, using concepts of attractor
dynamics in neuronal populations. We describe in detail two seminal
architectures -- a realisation of a closed-loop navigation controller
inspired by a Braitenberg vehicle and a sequence learning architecture
that makes use of plastic on-chip synapses to store sequences of
observations, and review a few more examples where on-chip plasticity
was used to learn along with behavior. Both these architectures were
realized on the ROLLS neuromorphic processor. Despite of the small
size of the network implemented, the neuromorphic processor is capable
of produce robust behavior on a robotic agent in real-time.


A. Closed-loop sensorimotor control


The first neuromorphic architecture demonstrates how behavior of a
simple roving agent can be controlled by a spiking neuronal network.
Such behavior can be generated by a very simple neuronal system, as
has been demonstrated by V. Braitenberg with his classical &quot;Vehicles&quot;
that generate meaningful behavior in a structured environment based on
simple wiring of their sensors and motors *REF*. According to this
view, the most basic ability required to generate goal-directed
behavior is the ability to diﬀerentiate between diﬀerent sensory
inputs. In simple terms, the agent needs to be able to tell one
sensory state from another one. In terms of neuronal architecture,
this means that the system needs to represent combinations of spatial
and nonspatial features, in order to select the spatial target for a
movement. Note that such combinations are also generated in deep
convolutional neural network architectures in diﬀerent feature maps.
The spatial component, however, typically gets &quot;lost&quot; in over layers
of the network that is trained for a recognition task. The first part
of our architecture achieves such diﬀerentiation or representation of
sensory states (note, we are showing a small scale example here on a
chip with 256 spiking neurons).


Fig. 4 shows a neuronal architecture that realizes one of the
Braitenberg&apos;s controllers on the neuromorphic device ROLLS. We used a
WTA network to represent visual input obtained by a neuromorphic
event-based camera Dynamic Vision Sensor (DVS), mounted on a miniature
robotic vehicle Pushbot. In particular, neurons in two WTAs receive an
external spike for each event in their receptive field: the &quot;Target&quot;
and the &quot;Obstacle&quot; populations in the figure. Each physical neuron on
the ROLLS that is assigned to belong to the Target WTA network is
stimulated by visual events from the upper half of the DVS: Each
neuron in the Target WTA &quot;observes&quot; a vertical column of the DVS
frame. Because of the soft-WTA connectivity, activity bumps emerge in
the target WTA that correspond to locations of salient visual inputs
in the field of view (FoV) of the robot. In this simple example, the
target direction is set by a blinking LED of the second robot, which
can be observed in the upper half of the FoV. Objects in the lower
half of the FoV are considered obstacles and drive the &quot;Obstacles&quot;
neuronal population shown in the upper part of the architecture in
Fig. 4. Thus, in the visual part of the controller, we diﬀerentiate
between obstacles and targets based on the location of the input on
the vertical axis of the FoV and we diﬀerentiate between locations (or
directions) of input based on the horizontal coordinate of the DVS
events.


Note that the physical instatiation of neurons on the ROLLS chip makes
this architecture simple and elegant: no time-multiplexing and state-machine logic is
needed, in fact no softwarebased arbitration or &quot;algorithm&quot; is used
for processing. Instead, we have created a closed-loop dynamical
system that processes sensory inputs and creates a representation in
real, physical time. By connecting events from a camera to diﬀerent
neurons through synaptic weights that realize receptive fields of
these neurons, we represent the visual input in neuronal substrate.


FIGURE


In this representation, each active neuron signals that there was some
input coming from the portion of the sensor that this neuron observes.
If several objects are present in front of a camera, several neurons
will be active. In the Target population, moreover, the WTA
connectivity makes sure that a single target location is selected and
distractors are suppressed *REF*.


On the motor side, the visually induced representation of the location
of potential obstacles represented by a neuronal population on the ROLLS chip is &quot;wired&quot; to
neurons that represent movement. These movement neurons, if active,
cause the robot to turn either to the right or to the left. Thus, each
of the two motor populations in Fig. 4 activates a motor primitive
that causes the robot&apos;s movement. In particular, the rotational
velocity of the robot is set proportional to the firing rate of the
respective (left or right) motor population. Presence of an obstacle
also makes the robot to slow down, activity in the Obstacles
population inhibits the &quot;Speed&quot; neuronal population. The firing rate
of this latter population sets the robot&apos;s forward speed.


Overall, the simple neuronal architecture shown in Fig. 4 allows the
robot to drive around, avoiding obstacles and approaching targets
*REF*. This behavior is produced by a dynamical system, created
by the sensorimotor &quot;embodiment&quot; of the robot, situated in an
environment, and the neuronal system that closes the behavior loop,
connecting perception to motor control. This controller does not
include any algorithmic arbitration: the sensory signals (DVS events
and Gyroscope measurements) directly drive neurons and, eventually,
the motors. The neuronal architecture ensures that a correct behavior
is produced. The fact the neurons on the ROLLS chip are instatiated
physically makes such eﬃcient direct connection possible, reducing
demands on the memory and arbitration that are usually managed by the
CPU.


The neuronal architecture presented here does not include any
learning. Indeed, this architecture is wired for the particular
task, although the precise neuronal parameters can be found by a
machine learning procedure *REF*, instead of human-labour tuning. In
the next section, we present a neuronal architecture on the ROLLS chip
that includes learning using plastic on-chip synapses. This
architecture is one of our recent examples that show how
representations -- of temporal or spatial behaviorally-relevant
patterns, such as sequences or maps, -- can be learned using
principles of attractor dynamics in hardware with explicit space and
time.


B. Learning sequences in a neuromorphic device


Recently, we have implemented the basic serial order sequence learning
model based on Dynamic Neural Fields *REF* on the ROLLS chip *REF*.
In this architecture, a WTA population represents the content of the
items in a sequence (here, location of a target on the horizontal axis
of the DVS&apos;s FoV). Other neuronal populations represent serial order
positions along the sequence: first, second, third, etc. ordinal
group. Each group of these ordinal neurons is connected to the content
WTA with plastic synapses that are updated when an ordinal neuron and
a WTA neuron are active at the same time, according to a local
synaptic plasticity rule. Groups of memory neurons create sustained
activation and keep track of the position in the sequence in
periods of sequential transitions, when ordinal groups are inhibited.
This inhibition is induced by a condition-of-satisfaction (CoS) system
-- a group of neurons that is activated when an item in the sequence
has been successfully executed *REF*.


FIGURE


In *REF* we have shown how sequence of states can be learned and
replayed by a robotic agent, whose sensors and motors are interfaced
to the neuromorphic device implementing the sequence learning
architecture in Fig. 5. In this example, again, the physical identity
of neurons is important to be able to eﬃciently, directly distribute
activity patterns in the neuronal architecture. Moreover, the ability
of the attractor networks to bridge diﬀerent amounts of time is
critical here: note that during sequence learning and production, each
item in a sequence can take diﬀerent - and not known in advance - time
intervals. Neuronal dynamics can sustain these long time intervals,
because stable activity bumps are created in the WTA neuronal
population and in the ordinal groups. No clock is needed to keep track
of time in these neuronal systems explicitly, although storing typical
durations of actions is also possible in the neuronal population
dynamics *REF*.


Another example of a neuro-dynamic architecture built using attractor
networks and profiting from explicit representation of space and time
in mixed signal neuromorphic devices is a neuromorphic
self-localisation and map formation architecture 
*REF*. In this system, first, a WTA neuronal population keeps track of the
correct heading of the agent, performing path integration based on the
motor commands sent to the robot. Another neuronal population keeps


track of the position of the robot in an environment. The plastic
synapses of the ROLLS chip are used to learn a simple map of the
environment as the robot navigates it and senses walls with a bumper.
The map is eﬀectively an association between the representation of
position (and orientation) of the robot and a neuronal representation
of a collision. Learning happens in the moment when the event induced
by the collision with an object activates the &quot;Collision&quot; population
of neurons. Co-activation of these neurons and neurons that represent
the current position in real time leads to increase of plastic
synapses between these two groups, forming a collisions map as the
robot explores the environment.


The same principle has been used to develop a neuromorphic PI
controller that triggers learning of a mapping from the target speed
of a robot to a motor command that realizes this speed *REF*. Such
mapping is an instantiation of a simple inverse model, which was
learned using plastic synapses on the ROLLS chip. Here, learning was
triggered when the PI controller (realized using the same principles
of population dynamics and attractor WTA networks) converges and
activates a zero-error neuronal population. Again, in this
architecture sensory inputs drive neuronal representations in real
time and learning is activated autonomously.


In all these neuromorphic architectures, a neuronal system is designed
that connects sensors and motors to solve a particular task. Learning
is reserved to certain portions of these architectures -- e.g., a
mapping between a sensory and motor space, or between representation
of the ordinal position and perceptual content. The WTA connectivity
of neuronal populations that represent perceptual states ensures that
representations are localised and stabilised, limiting learning both
in time and in space. In *REF*, we show how on-chip plasticity
combined with WTA structure can also be used to learn to diﬀerentiate
patterns in an unsupervised manner, while *REF* shows how
neuronal populations can be used to perform arithmetic operations,
such as summation and substraction, required, e.g., to realise a PI
controller in a neural network or to perform reference frames
transformations. The latter work emphasises that some computation that
can easily be solved on a conventional von Neunmann computing platform
might require rethinking and design of a neuronal architecture in
neuromorphic computing devices.


C


Neuromorphic computing represents a promising paradigm for artificial
cognitive systems that may become an enabling element for the design
of power-eﬃcient, real-time, and compact solutions for electronic
devices that process the sensory data and generate behavior in
real-world -- changing and complex -- environments. To minimize power
consumption it is important to


match the dynamics of neuromorphic computing elements to the time
scale of physical processes that drive them and which the devices
control. The impact of this approach is significant, because in
addition to autonomous robots, &quot;cognitive agents&quot; represent also
low-power alwayson embedded sensory-computing systems (e.g., in
cell-phones or wearable devices), intelligent wireless sensors (e.g.,
for Internet of Things -IoTapplications), or intelligent
micro-bio-sensors (e.g., for personalized medicine, brain-machine
interfaces, or prosthetics), or other types of micro-scale autonomous
devices that extract structure from the data they acquire through
their interactions with the environment and take decisions on how and
when to act (to transmit information, power-up further processing
stages, etc.)


Although many of the organizing principles of nervous systems have
successfully been adopted for the design of artificial intelligence
systems, two of the most powerful ones, i.e., that of letting time
represent itself, and that of using physical instantiations of
parallel circuits rather than single time-multiplexed ones, are not
yet fully exploited. Here we presented examples of systems that
implement also these principles and described a computational approach
that extends the temporal processing abilities of such device to
arbitrary time scales using attractor dynamics and the DNF framework.
We have discussed several examples of neuro-dynamic architectures that
make use of the physical instantiation of spiking neurons in hardware
and their real-time dynamics, matched to biological time-scales. We
believe these examples represent the first steps toward the
realization of neuromorphic systems and computing architectures
optimally suited for tasks in which behavior needs to be generated by
autonomous neuromorphic agents in real-time, while staying adaptive in
complex environments.