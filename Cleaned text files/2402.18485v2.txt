A Multimodal Foundation Agent for Financial Trading: Tool-Augmented, Diversified, and Generalist


INTRODUCTION


Financial markets are essential for economic stability, facilitating capital allocation and risk management. Financial trading systems, developed from technical analysis strategies [*REF*], enhance these markets by enabling efficient trading. Rule-based trading systems are rigid and struggle to adapt to market volatility, often resulting in underperformance in evolving markets. Reinforcement learning-based systems [*REF*] demonstrate enhanced adaptability but encounter substantial obstacles, such as the need for extensive training data and the inexplainability of decision-making processes. Additionally, they struggle with generalizing across diverse market conditions, are sensitive to market noise, and often fail to integrate multi-modal market intelligence like news and reports into their analysis. The financial trading landscape demands more advanced machine-learning methods to address complex market dynamics, seeking to move beyond the limitations of rule-based and RL methods.


Recently, Large Language Models (LLMs) have showcased their potential in a range of decision-making tasks when applied in AI agents [*REF*, *REF*, *REF*, *REF*], marking a significant expansion beyond natural language processing into more complex, task-specific functions. This advancement includes the integration of memory and planning modules, which enable these agents to adapt within dynamic environments, akin to human cognitive processes. This evolution has been further pushed by the advent of multimodal LLMs like GPT-4V [*REF*], which enhances the capabilities of LLMs by processing both textual and visual data. Moreover, the integration of tool-augmented models like Toolformer [*REF*] empowers LLMs to utilize external tools, thus elevating their decision-making abilities in complex scenarios. This combination of adaptability and enhanced processing capabilities offers new possibilities in fields such as fintech, where nuanced analysis and adaptation are important. LLMs have demonstrated remarkable capabilities in analyzing and interpreting financial data, as evidenced by developments like BloombergGPT [*REF*], and FinGPT [*REF*]. However, there is a natural gap between QA tasks and sequential decision-making in trading. Although FinMEM [*REF*] is an LLM trading agent with a humanaligned memory mechanism and character design, the full capabilities of LLMs as comprehensive autonomous trading systems remain underexplored, particularly in their ability to interpret multimodal data and utilize diverse tools. The challenges in navigating the complexities of financial markets are identified as follows:


Ch1: Insufficient Multimodal Data Processing Ability. Processing the extensive range of market intelligence, including numerical, textual, and visual information, presents significant difficulties.
Advanced analytical methods are required to extract key insights from such diverse data to predict market trends.
Ch2: Lack of Targeted Information Retrieval. Some agents mix up retrieval with their main tasks, relying only on brief target task summaries to retrieve historical data. This absence of precise searching introduces too much irrelevant data into the results, which detracts from overall performance.
Ch3: Adaptability in Rapidly Evolving Markets. Financial trading requires the ability to quickly adapt to fluctuating market conditions. Traditional methods often fall short, highlighting the necessity for models capable of responding to real-time data and adjusting strategies according to historical market trends.
Ch4: Integration of Domain Knowledge. Current models often struggle to integrate established methods such as expert guidance and advanced trading tools effectively, leading to a decline in both the effectiveness and depth of market analysis. Ch5. Reasoning for Actions. The black-box nature of many sophisticated AI models, directly giving results of decisions without providing the reasoning process.


To address the challenges of adapting the multimodal LLMs to the dynamic and information-rich financial trading tasks, we present FinAgent, a multimodal foundation agent that integrates both textual and visual information for a comprehensive analysis of market dynamics and historical trading patterns. Specifically, FinAgent&apos;s market intelligence module processes multimodal data, such as numerical, textual, and visual, to provide precise analysis of financial market trends, offering insights for future trading tasks (Ch1). A uniquely designed dual-level reflection module is developed, capable of not only rapidly adapting to market dynamics but also enhancing the agent&apos;s ability to learn from historical data and improve its decision-making process (Ch2). FinAgent introduces a diversified memory retrieval system for the market intelligence and reflection modules, separating trading and retrieval tasks to enhance focus on their specific functions and minimize noise in the results (Ch3). Finally, the decision-making module incorporates expert knowledge, comprising both supplementary expert guidance and auxiliary expert strategies, to guide the agent&apos;s decisions. This emphasis on providing reasoned explanations for actions fosters trust in its financial decisions (Ch4 &amp; Ch5). Specifically, our contributions are four-fold:


We introduce the market intelligence module, which is able to extract key insights from multimodal datasets encompassing asset prices, visual representations, news, and expert analyses, offering a multifaceted view across various markets.
We not only generate summaries for trading tasks but also provide query fields for retrieval tasks. These query texts include different retrieval types, tailored to enable focused retrieval of specific types of information.
Our two-level reflection module combines a low-level reflection that analyzes market price movement for insights, while the high-level reflection assesses past trading decisions for improvement, emulating the learning process in decision-making.
We employ a suite of tools in FinAgent, including expert guidance and technical indicator-based advanced trading strategies, to infuse domain knowledge in financial trading.


With comprehensive experiments on 6 financial datasets, including stocks and Crypto, FinAgent significantly outperforms 9 state-of-the-art baselines in terms of 6 financial metrics with over 36% average improvement on profit. Specifically, a 92.27% return (a 84.39% relative improvement) is achieved on one dataset. Notably, FinAgent is the first advanced multimodal foundation agent designed for financial trading tasks.


RELATED WORK


LLM Agents for Decision Making


The field of artificial intelligence and natural language processing has reached a significant milestone with the emergence of LLMs like ChatGPT [*REF*] and GPT-4 [*REF*].
BloombergGPT [*REF*] introduced the first LLM in the finance domain, combining financial and text data, but without public access. FinGPT [*REF*] proposed the first open-source finance LLMs, incorporating reinforcement learning with human feedback.


While LLMs achieve impressive performance in NLP tasks [*REF*, *REF*], more works explored the capability of LLMs to function not just as language processors but as agents capable of performing complex tasks. Initiatives like AutoGPT [*REF*] and MetaGPT [*REF*], Voyager [*REF*], and AI agents [*REF*, *REF*] expand LLMs&apos; capabilities to complex tasks involving reasoning and collaboration, significantly advancing technology and impacting daily life. FinMEM [*REF*] presents an LLM agent with a human-aligned memory mechanism and character design for automated trading.


Recently, there has been growing interest in enhancing LLM agents with external tools and modular methods as AI agents.


TABLE


Method


TABLE


Tool-augmented Language Models (TALM) [*REF*, *REF*, *REF*, *REF*] have been evaluated through recent benchmarks, such as ScienceQA and TabMWP [*REF*, *REF*, *REF*, *REF*, *REF*, *REF*], designed to assess their ability to tackle intricate reasoning challenges, particularly those requiring the use of external tools. These improvements enable LLMs to retrieve current information through web searches [*REF*] and to apply specialized knowledge from external sources [*REF*].


However, a major limitation of LLM agents is their dependence on text-based information, which limits their perception and interaction with the environment. Introducing models equipped with vision capabilities, such as the latest iteration of GPT-4V [*REF*], marks a pivotal breakthrough. There has also been the emergence of multimodal agents [*REF*, *REF*, *REF*] utilizing the visual capabilities of multimodal large language models to perform tasks previously unachievable by text-only agents. Most existing LLMs in finance focus on NLP tasks, and their potential in trading is not fully explored. FinAgent is a multi-modal, tool-augmented LLM foundation agent for financial trading to bridge the gap.


AI for Financial Trading


AI techniques have been widely used in various financial trading of FinAgent, which integrates LLMs into the RL pipeline to enable flexible reasoning and decision-making in financial trading.


Financial Trading as MDP


A financial trading task involves sequentially making investment decisions (e.g., buy/sell stocks) to maximize total profit under certain risk tolerance [*REF*]. We formulate it as an MDP under a classic RL scenario following [*REF*, *REF*], where an agent (investor) interacts with an environment (the financial market) to make actions (investment decisions) at discrete time to earn rewards (profits). The MDP is constructed by a 5-tuple S,,, ùëÖ, ùõæ. Specifically, S is a finite set of states. is a finite set of actions. The state transition function A (A T): S S 0, 1 encapsulates transition probabilities between states based on chosen actions. The reward function ùëÖ: S ùëÖ quantifies the immediate reward of taking an action in a state. The discount factor is ùõæ 0, 1. A policy ùúã: S 0, 1 assigns each state ùë† S a distribution over actions, where ùëé has probability ùúã ùëé ùë†. During training, the agent is in charge of making investment decisions at each time step through one whole trading period and tries to learn an optimal policy (investment strategy) popular for stock prediction since they are specifically designed to capture temporal patterns in sequential data. Another direction of work employs graph-based DL models to model pair-wise relations between stocks. For instance, Feng et al. [*REF*] enhance graph convolutional networks (GCNs) with temporal convolutions for mining inter-stock relations. Sawhney et al.
[*REF*] focus on stock industry data and links between company CEOs. Tree-based models [*REF*] also achieve robust performance. Xu and Cohen [*REF*] propose a variational autoencoder architecture to extract latent information from tweets. Chen et al. [*REF*] enhance trading strategy design with the investment behaviors of professional fund managers. Other data sources such as economics news [*REF*] and earning calls [*REF*] are also used to improve the prediction performance. Sun et al.
[*REF*] introduce a novel three-stage ensemble learning method. Reinforcement learning [*REF*] has achieved success in finance with algorithms, platform [*REF*], and evaluation toolkits [*REF*]. However, most of these methods are hindered by their focus on price data and limited generalization, necessitating advanced techniques that can integrate multimodal intelligence and navigate complex market dynamics.


Specifically, we focus on single asset (e.g., stock or Crypto) trading. A state represents RL agents&apos; perception on the financial market based on price information, limited order book [*REF*], technical indicators, trend prediction [*REF*], financial news [*REF*], experts&apos; investment behaviors [*REF*] and overall market status [*REF*]. The action space includes three choices to buy, sell or hold the asset [*REF*, *REF*]. The reward function leverages the change of market capitals (earned/lost money) [*REF*] with consideration of commission fee [*REF* *REF*].


Problem Formulation


We further integrate multimodal LLMs into the RL framework [*REF*], enabling the flexible definition of the reasoning processes. In FinAgent formulation, we focus on the necessity of defining, learning, and applying these processes independently. We extend the classic RL optimization problem for FinAgent as follows: 


FORMULA


PROBLEM FORMULATION


We first introduce the Markov Decision Process (MDP) formulation of financial trading. Later on, we provide the formal formulation where ùëüùë° is the reward at the time step ùë° that depends on the environmental state ùë†ùë° and action ùëéùë°. ùúá are specialized modules that encapsulate beneficial internal reasoning processes. Note that a state contains multimodal information including textual, numerical, and visual data. Faced with a task ùúÜ and equipped with a memory daily data about the macro environment, current market conditions or investors&apos; sentiments that inform investment and trading decisions.
In FinAgent, we harness the power of both the latest and historical news, financial reports, and asset prices related to the where ùúô is a task-relevant prompt generator. The prompt is then passed to a multimodal LLM, from which a response is generated. Finally, the response is parsed through the task-specific action parsing function ùúÜ to perform compatible actions in the environment. FinAgent is a multimodal LLMs agent in this framework specifically designed for financial trading, which contains five core modules, namely market intelligence module (M), memory module (Mem), low-level reflection module (L), high-level reflection module (H) and decision-making module (D). We can define the ùúáùë° and targeted asset in order to inform and optimize trading decisions.
Latest Market Intelligence. This module mainly consists of asset news and daily asset prices. However, it is not confined to these elements alone. Any information impacting the market can be encompassed within our framework as part of the latest market intelligence. The objective of this component is to evaluate the sentiment1 of each market intelligence item regarding its influence on future asset prices and to provide a detailed summary of whether the market has recently exhibited bearish or bullish tendencies, thereby assisting in informed decision-making.


Nevertheless, historical data can offer insights into patterns that might influence future pricing and potentially affect current and upcoming market dynamics. For instance, if a past product launch significantly boosted a company&apos;s stock, a recent launch might have a similar effect. We hope to incorporate these historical experiences where ùëÄ, ùëÄùëíùëö, ùêø, ùêª, ùê∑ correspond to each module respectively ùëÄùëíùëö‚àó,ùúÜ denotes the memory of ùëÄ, ùêø, and ùêª. ùêæùê∂ and ùëáùê∂ represent the Kline chart and Trading chart. ùúôùúÜ denotes the prompt generator corresponding to each module asso‚àóciated with task ùúÜ.


Therefore, with the integration of memory mechanism, augmented tools, and several designed modules, the overall objective of FinAgent is to find policies as described in Eq. to optimize total discounted returns: ‚àëÔ∏Å and patterns into FinAgent&apos;s considerations. This inspired us to add two additional functional layers: retrieving relevant information from past market intelligence and summarizing key insights and historical experiences from them.


Diversified Retrieval Operation. A straightforward approach involves using the summary of the latest market intelligence as the query text and then employing an LLM to extract its semantically rich embeddings. This allows for retrieving past market intelligence i) the summary of recent market intelligence is primarily aimed with similar content through vector similarity. However, adopting this approach inevitably comes with two significant shortcomings:


FINAGENT FRAMEWORK


As shown in Figure *REF* the FinAgent framework comprises five core modules. Specifically, the market intelligence module ([¬ß4.1]) is responsible for collecting, collating, summarizing, and analyzing market information, which includes daily updates on stock news, prices, and monthly and quarterly financial reports. The low-level reflection module ([¬ß4.3]) establishes the inherent correlation between market intelligence and price changes. And the high-level reflection module ([¬ß4.3]) involves reflecting on market conditions, price changes, and other factors in the context of outcomes from past trading decisions, which aims to derive insights from previous experiences and identify potential improvement in profitability by assessing the efficacy of historical decisions and offering recommendations for future decision-making processes. The primary role of the memory module ([¬ß4.2]) is to support the aforementioned three modules by offering storage capabilities and vector retrieve functions. The tool-augmented decision-making module ([¬ß4.4]) integrates the aforementioned information, along with augmented tools and trader preferences, to make final investment decisions with a comprehensive analysis.


Market Intelligence Module


To make profitable investment decisions, it is beneficial to collect, summarize, analyze, and extract key insights from various multimodal financial data sources. We design the market intelligence module to achieve this goal. Market intelligence typically involves at supporting subsequent trading decision tasks, not for retrieval tasks. The significant gap between these two objectives can lead to unsatisfactory retrieval results; ii) some noise unrelated to the retrieval task may be contained in the summary, directly affecting the retrieval results. To address these challenges, diversified retrieval is implemented in FinAgent. Specifically, we have introduced an additional query text field to the output of the latest market intelligence component, which is dedicated to serving retrieval tasks in parallel with the summary that caters to trading tasks. It is worth emphasizing that we can define various retrieval types3 to enable an agent to retrieve past market intelligence from multiple perspectives, in multiple senses, and with a purpose. As shown in Figure *REF* there are ùëÄ retrieval types, so retrieving top ùêæ historical market intelligence separately can form a combination of ùëÄ ùêæ market intelligence in the past. This approach assigns specific retrieval types to each piece of historical information accompanying the summaries. This nuanced labeling facilitates a more targeted and efficient search and retrieval process.


Past Market Intelligence. Once similar past market intelligence is searched, it undergoes the summarising step, delivering key insights tailored to augment trading decisions. This meticulous approach ensures that only the most relevant information is incorporated, mitigating the impact of noise and maximizing the utility of historical data in informing trading strategies.


FIGURE 1


Memory Module


The memory mechanism [*REF*, *REF*, *REF*] is crucial in LLM Agents for effectively handling extensive texts, grasping the context, ensuring the coherence of conversations, and improving the agent&apos;s comprehension and logical abilities. In the context of multimodal LLM Agents for financial trading, memory mechanisms play a crucial role in three main aspects: i) Acuity. This feature allows multimodal LLM agents to harness market news, financial reports, and associated information for enhanced market forecasting. By analyzing historical data and current events and understanding their potential impact on market trends and asset prices, multimodal LLM agents can construct more accurate market models, forecasting future price movements and market dynamics to support trading decisions effectively. ii) Adaptability. As price trends and market environments evolve rapidly, memory mechanisms enable multimodal LLM agents to swiftly learn from new market data and price trends, adapting to these changes. This adaptability is achieved through continuous analysis of market conditions and trading outcomes, enabling multimodal LLM agents to dynamically adjust their trading strategies to cope with market volatility and capitalize on new trading opportunities. iii) Amendability. Memory mechanism also empowers multimodal LLM agents to remember past decision-making errors and successful trades for deep reflection and analysis. Through this self-evaluation, multimodal LLM agents can identify the factors leading to mistakes, avoiding the repetition of the same errors in future trading decisions. This ongoing learning and adjustment process aids in continuously optimizing the trading performance and output quality of multimodal LLM agents, resulting in more robust and efficient trading strategies.


To realize the 3A superiority - Acuity, Adaptability, and Amendability - in the memory mechanism, our development of the memory module employed a vector storage architecture. This module is composed of three main components: market intelligence memory (service for ([¬ß4.1])), low-level reflection memory (service for ([¬ß4.3])), and high-level reflection memory (service for ([¬ß4.3])).
As illustrated in Figure *REF* the summarize operation creates a query text field for each module, enhancing memory storage and retrieval processes. Specifically, the unique feature of the market intelligence module lies in its ability to retrieve past market intelligence through query text. This module uses vector representations to streamline the storage and retrieval process, matching data based on the similarity of query text vectors. All analyses and summaries from the market intelligence, low-level reflection, and high-level reflection modules are stored in the memory module. This integration equips the agent with a broad spectrum of both the latest and historical market data and insights, bolstering its decision-making capabilities.


Reflection Module


A reflection module is incorporated into the agent&apos;s design to emulate the cognitive learning process inherent in human decision-making. The reflection framework is divided into low-level reflection and high-level reflection, each serving distinct purposes to enhance the agent&apos;s trading decisions. The low-level reflection module involves reflecting on the relationship between the agent&apos;s observations (e.g., news, financial reports, Kline chart and technical indicators) and the resultant price movements in the market, drawing connections between the provided information and the actual price changes. Whereas the high-level reflection step examines past decisions, tracking both the agent&apos;s actions and the subsequent price movements in order to learn from past successes or mistakes.
Low-level Reflection Module The primary focus of the low-level reflection module is to analyze the connection between the given market intelligence together with the Kline chart and technical indicators and past and future price changes to enhance decision-making. After taking in the price change data, the module generates detailed analysis for varying temporal horizons, spanning short-term, medium-term to long-term perspectives. The emphasis is placed on identifying potential patterns in the price movements of the targeted stock and deriving insights from how the given market intelligence summaries and Kline chart analysis can lead to such price movements.
In order to facilitate future access and reference, the module generates a query field containing a concise summary of learned lessons, ensuring efficient retrieval and application of insights in subsequent decision-making endeavors.


FIGURE 2


TABLE 2


High-level Reflection Module The high-level reflection module is designed to provide analysis and reflections on past trading decisions. Besides the past trading decisions and their underlying reasoning, this module incorporates a graphical representation of buy and sell points on a trading chart, coupled with a cumulative return plot, to offer an intuitive representation of the efficacy of historical decisions. The initial phase assesses each trading decision&apos;s correctness, identifying successes and mistakes. Subsequently, the module recommends improvements or corrective actions tailored to each identified mistake or success, fostering a continuous learning process. Beyond individual decision analysis, the module generates overarching lessons from both successes and mistakes, providing a summary that can be adapted to future trading decisions and a query text to facilitate the retrieval of relevant reflections. This iterative learning process equips the agent with a dynamic knowledge base that evolves with each decision and allows the trading agent to draw connections between similar scenarios, applying learned lessons for more informed decision-making.


1. Tool-Augmented Decision-making Module The decision-making module integrates key inputs, including market intelligence summaries, low-level reflection about price movement analyses, and reflections on past decisions. Augmented tools with professional investment guidance and traditional trading strategies like MACD Crossover, KDJ with RSI Filter and Mean Reversion are also considered. The module analyzes sentiment in market intelligence, predicts bullish or bearish trends from price movements, reflects on lessons learned, and evaluates professional guidance and traditional indicators. Decisions are derived from combining insights from these analyses, also considering the current financial position, leading to a final decision---whether to buy, sell, or hold the asset. Leveraging the Chain-of-Thought (COT) approach and in-context learning principles, our trading decision-making module not only executes trades but also provides reasoning, ensuring that each decision is rooted in a comprehensive understanding of market dynamics and contextual knowledge.


EXPERIMENT SETUP


Our research aims to conduct a thorough evaluation of FinAgent&apos;s trading effectiveness, underscoring its unique capability to function efficiently with a significantly reduced historical data training window. This assessment also involves leveraging multimodal data inputs, incorporating both informational and agent-assistive augmented tools, along with a multi-perspective diversified retrieval.
This approach is intended to enhance the understanding of market dynamics and sentiments, enabling more comprehensive and logical decision-making processes along with substantiated explanations. To validate its effectiveness, we have conducted a series of experiments to address the following research questions (RQs):


RQ1: Is FinAgent outperforming current state-of-the-art trading agents and handling tasks that challenge other algorithms?
RQ2: What is the effectiveness of each component of FinAgent in contributing to its overall performance?
RQ3: Does the integration of augmented tools in FinAgent lead to a distinguishable improvement in its trading performance?
RQ4: How effective is the diversified retrieval in FinAgent?


Datasets


TABLE 3


To conduct a thorough evaluation of FinAgent, we evaluate it across 6 real-world datasets. These included five datasets from the US stock markets, and one is the cryptocurrency. Each of them has multiple forms of data that come from various sources. Specifically, i) Asset Price at the day-level, including price data for open, high, low, close, and adj close; ii) Visual Data consists of historical Kline charts and trading charts, which are visual representations of asset market data and trading process on a daily basis; iii) Asset News coverage with daily updates from various esteemed sources such as Bloomberg Technology, Seeking Alpha and CNBC Television, ensuring a diverse and thorough perspective on the financial markets; iv) Expert Guidance provided by financial experts as the auxiliary information, aiming to furnish a thorough and well-rounded comprehension of market status. We summarize statistics of the 6 datasets in Table [3]. and further elaborate on them in Appendix [B].


Our diversified portfolio includes five major stocks: Apple Inc.
(AAPL), Amazon.com Inc. (AMZN), Alphabet Inc. (GOOGL), Microsoft Corporation (MSFT), and Tesla Inc. (TSLA) and a prominent cryptocurrency named Ethereum (ETHUSD). This selection aims to showcase FinAgent&apos;s versatility and consistency across various financial assets. Chosen for their extensive news coverage and representation of different market sectors, these data provide a robust basis for assessing FinAgent&apos;s generalization capabilities across diverse financial environments. For dataset split, the data from the latter half of the year is allocated for testing (2023-06-01 2024-01-01) purposes, while the data from the penultimate year is utilized for training (2022-06-01 ‚àº 2023-06-01).


Evaluation Metrics


We compare FinAgent and baselines in terms of 6 financial metrics following [*REF*, *REF*], which include 1 profit metric: annual return rate (ARR), 3 risk-adjusted profit metrics: Sharpe ratio (SR), Calmar ratio (CR), Sortino ratio (SOR), and 2 risk metrics: maximum drawdown (MDD), volatility (VOL).
Detailed definitions and formulas are available in Appendix [C].


Baselines


We compare and evaluate the trading performance of FinAgent with four widely accepted conventional rule-based trading strategies (B&amp;H, MACD, KDJ&amp;RSI and ZMR) and five advanced algorithms.
Among these, SAC [*REF*], PPO [*REF*] and DQN [*REF*] are three models employed RL methods, FinGPT [*REF*] is based on LLM, and another is FinMem [*REF*] based on LLM Agents. A brief introduction to each method is available in Appendix [D].


Implementation Details


Although FinAgent&apos;s training and inference can be done without a GPU, we utilized a single NVIDIA RTX A6000 GPU for our benchmark methods.
To ensure equitable comparison, all benchmarks are conducted within the same RL environment for both training and evaluation. The following experiments related to FinAgent all have diversified retrieval if not specifically noted. Details on the benchmark and experiments setup are provided in Appendix [E].


EXPERIMENTAL RESULTS


Comparison with Baselines (RQ1). We compared FinAgent with 9 baseline methods in terms of 6 financial metrics. Table *REF* and Figure [3]. demonstrate our method significantly outperforms existing baselines, especially remarkable improvements in profitability, and setting a new benchmark in the field. The full results and case studies of FinAgent are avaliable in Appendix [I], [H]. FinAgent&apos;s performance on the five stocks, as measured by ARR% and SR, with enhancements of at least 10% and 19%, compared to the best-performing baseline, respectively. Notably, its performance on the TSLA dataset stands out even more, achieving 84% and 118% improvement, significantly outperforming all other baselines. Across all datasets, FinAgent is the only method that consistently outperforms the broader market in terms of profitability. In contrast, FinMem falls short on the AMZN dataset, where its ARR% is 40%, underperforming the market&apos;s Buy &amp; Hold (B&amp;H) strategy at 42%. This underscores the superior stability and robustness of FinAgent compared to other baselines. We can also observe that rule-based methods are optimal in controlling risk, but not outstanding in capturing returns. This is because rule-based model methods are robust to outliers and noise in the data and thus can reduce decision risk. It is worth noting that high returns often come with high risks. Hence, FinAgent represents a slight compromise on risk control. This result relates to our chosen investor preference of an aggressive trader. Therefore, FinAgent can slightly increase the risk to improve returns substantially.


TABLE 4 


FIGURE 3


Figure [3] illustrates that FinAgent&apos;s performance surpasses other methods regarding cumulative returns, particularly on the TSLA dataset.
Leveraging market intelligence and the reflection mechanism, FinAgent anticipates a significant stock price drop post-September 14, 2023. By taking a short position, it can effectively hedge against potential trading losses and generate high returns.


It&apos;s important to note that our approach yields slightly lower returns than FinMem on the cryptocurrency ETH, primarily because our auxiliary agents are specialized strategies tailored for stocks, not for cryptocurrencies with higher trading frequency. Further insights from the ablation study section for FinAgent reveal that employing a generalized auxiliary agent for cryptocurrency could by 14% to 44%. When comparing the ML and MLH, the addition of the high-level reflection module significantly enhances the ARR% and SR, while notably reducing risk. This improvement comes with a minor trade-off: a slight 7% rise in MDD% for TSLA. Compared to MLH and MLHT, there&apos;s a minor improvement in stock profitability. However, the performance of ETH cryptocurrency dropped by over 20% due to the introduction of rule-based methods as auxiliary agents, which are specialized only for stocks.


TABLE 5


This significant difference will be elaborated upon in the forthcoming ablation studies.


ABLATION STUDIES


Effectiveness of Each Component (RQ2)


In Table [5] we study the effectiveness of market intelligence (M), low-level reflection (L), high-level reflection (H) and augmented tools (T). When compared to using solely M and ML, the integration of the low-level reflection module leads to an impressive increase in ARR% by 45% to 101% for TSLA, and ETHUSD, and cutting risk by 14% to 44%. When comparing the ML and MLH, the addition of the high-level reflection module significantly enhances the ARR% and SR, while notably reducing risk. This improvement comes with a minor trade-off: a slight 7% rise in MDD% for TSLA. Compared to MLH and MLHT, there is a minor improvement in stock profitability. However, the performance of the ETH cryptocurrency dropped by over 20% due to the introduction of rule-based methods as auxiliary agents, which are specialized only for stocks.
Effectiveness of Augmented Tools (RQ3)


As previously discussed, while the addition of auxiliary agents to stock investments results in profit improvements, it causes a considerable performance decline in cryptocurrencies. Thus, we conducted an experiment where decisions are made solely by augmented tools, such as rule-based methods serving as auxiliary agents. In this experiment, various auxiliary agents provided both decisions and their explanations. These inputs are directly integrated into FinAgent&apos;s decision-making module without other modules&apos; involvement in the final decision process.


As shown in Table [4] and Table [5], the 16% ARR% for solely T method starkly contrasts with the 29% ARR% of B&amp;H in ETHUSD, highlighting the inefficacy of the stock-specific rule-based methods for cryptocurrencies and demonstrating that introducing FinAgent significantly affects performance. This suggests that investors should not indiscriminately add auxiliary agents for investment support. Instead, they must meticulously select agents that match the characteristics of the market to avoid detrimental impacts on performance.


Effectiveness of Diversified Retrieval (RQ4)


As shown in Figure 4(a), we compare the performance of FinAgent with or without diversified retrieval on AAPL and find that the use of diversified retrieval contributes to a significant improvement in ARR and SR. As shown in Figure 4(b), we extract different types of market intelligence that AAPL diversified retrieval provides daily on the validation set and filter out individuals with the same content under the same type. We perform t-SNE visualization of its LLM-extracted embedding and observe a clear distinction between different retrieval types, proving the effectiveness of our method.


FIGURE 4


CONCLUSION AND FUTURE WORK


This paper introduces FinAgent, a financial trading agent powered by LLM that exhibits high reasoning ability and generalizability.
FinAgent is a multimodal agent that integrates both textual and visual data, enabling a comprehensive understanding of market dynamics and historical trading behaviors. It is designed to independently leverage auxiliary tools for detailed market data analysis over different time scales. With its multi-perspective and diverse retrieval approach, FinAgent effectively identifies correlations between current market conditions and past market patterns and trends and integrates market information to make final and effective decisions. For future research directions, we will apply FinAgent to other financial tasks, such as portfolio management, where LLM is used to rank each stock according to the observed market intelligence and make the stock selection.