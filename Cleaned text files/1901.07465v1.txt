Collective learning from individual experiences and information transfer during group foraging


Introduction


Learning processes are of primary importance for many living organisms to adapt to their environments [*REF*; *REF*]. During foraging, animals can take movement decisions based on past successful experiences, resulting in changes of behaviors over time and an improved exploitation of resources [*REF*; *REF*]. The use of spatial memory is well documented in many species [*REF*; *REF*], and ecological knowledge can be the result of continuous learning throughout the life of an individual. Large herbivores that were introduced into a novel environment took several years to adopt a phase of home-range movements [*REF*]. Adult seabirds like gannets have a better knowledge of profitable zones and forage more efficiently than young individuals [*REF*]. Markovian random walk models, that assume that foragers lack memory, have proven useful to study how foraging success depends on particular movement patterns and the distribution of resources [*REF*; *REF*]. However, such models do not consider the fact that animals perform some actions repeatedly and they cannot address the role played by experience on movement decisions [*REF*].
Recent mechanistic models have further incorporated memory-based movements, showing how spatial learning can emerge with time: learning is noticeable, for instance, by frequent revisits to certain locations rich in resources [*REF*; *REF*] or through the emergence of home ranges and preferred travel routes [*REF*; *REF*]. Similar theoretical approaches have been useful to understand insect navigation [*REF*; *REF*].


On the other hand, many animal species live in groups [*REF*; *REF*] and one may ask how individual spatial learning may be affected, or enhanced, by the presence of others. Sociality brings many known benefits, such as a decreased risk of predation [*REF*; *REF*; *REF*; *REF*] or improved capacities for sensing and making decisions [*REF*; *REF*; *REF*] while searching for food in uncertain environments [*REF*; *REF*; *REF*; *REF*]. When individuals forage in groups, foraging success can be enhanced by information transfer between group members [*REF*; *REF*; *REF*; *REF*].
Social insects like honey bees [*REF*] and ants [*REF*] are classical examples of collective foraging where information is transferred between individuals by external means (chemical trails or nectar sharing). Similar principles can apply to vertebrates, where information is not necessarily stored in the environment but within the individual, such that individuals can use their internal memory to visit places located beyond their perceptual range. Species such as macaques [*REF*], cliff swallows [*REF*], gazelles [*REF*], elephants [*REF*] and hyenas [*REF*] communicate over large distances (sometimes of several kilometers) by vocalizations. The information which is transferred in this way can have a positive impact on the foraging success in social groups [*REF*]. In killer whales, old females tend to lead the group during collective movement when prey abundance is low, thus transferring valuable ecological knowledge [*REF*]. In spider monkeys, central individuals in the social network tend to be followed more when they are knowledgeable about available feeding sources than other, non-central individuals [*REF*].
Animal groups on the move, where individuals interact locally, are prone to exhibit collective behaviors [*REF*; *REF*; *REF*; *REF*] through which the group can accurately pool information about the current state of the environment [*REF*; *REF*; *REF*; *REF*]. Such &apos;&apos;collective intelligence&quot; can allow a rapid response to external signals. The effects of interactions on collective motion [*REF*; *REF*] and their impact on foraging success [*REF*] have been well studied in systems of agents without memory. When the dynamical rules are local in time, they only depend on the current state of the system and not on its previous history. In contrast, the mechanisms by which coordinated behaviors emerge from interacting individuals with memory are much less understood. Modelling approaches have shown that a physiological memory can guide individual foraging behaviour and influence social interactions, ultimately affecting group dynamics [*REF*; *REF*].
However, these former models focus on nutritional states rather than movement and space use. We wish to quantify here, by means of a spatially explicit agent based model, how both memory use and interactions with peers can contribute to improving the foraging success of a group as a whole.


We define collective learning as a coordinated change of behavior within a group, resulting from individual experiences and information transfer between group members [*REF*]. During collective learning, individuals with different experiences may acquire valuable information through interactions with others, possibly resulting in an increased foraging success compared to what isolated individuals would typically achieve.
The structure of social networks is likely to be relevant in such processes, since certain individuals are more important than others for transmitting information on food locations [*REF*].
We develop a simple agent based model to show that collective learning can contribute significantly to successful group foraging in complex environments, namely, those composed of many resource sites of unequal values, representing food or water holes. When the agents can use memory to visit places located beyond their perceptual range, we seek to determine whether collective behaviours such as spatial aggregation can emerge from a dispersed population with no initial information about resources, and whether such aggregation takes place around the most profitable places. It is also of our interest to study the effects of the foragers&apos; interaction network on collective learning.


Model


The collective model presented here is an extension of another one for a single forager with reinforcement learning, exposed under slightly different forms in [*REF*; *REF*; *REF*; *REF*; *REF*]. To summarize, the motion of the individuals is assumed to be driven by the combination of two basic movement modes: standard random walk displacements and preferential returns to places visited in the past. In the latter mode, a forager (assuming first that it does not interact with others) chooses a particular site for relocation with a probability proportional to the accumulated amount of time it previously spent at that site. Therefore, the sites that are often occupied have a higher probability of being revisited in the future: they are linearly reinforced [*REF*]. Since these preferential dynamics depend on history, it implies that the forager has the ability to remember which sites were previously visited and for how long. To incorporate interactions between several foragers, we assume here that memory is shared through constant communication. Hence, in the memory mode, a forager can relocate to a previously visited site chosen either from its own experience or from the experience of another group member. A second important aspect is the modeling of the resource landscape: each resource site is characterized by a weight or profitability *MATH*.
A forager located at a resource site *MATH* stays on it at the next time step with probability *MATH* or moves with probability *MATH*.
These rules are detailed as follows.


Environment. We consider discrete lattices, of *MATH* sites in one dimension (*MATH*) and of *MATH* sites in two dimensions (*MATH*), with unit spacing and reflective boundaries. The site coordinate *MATH* is an integer (*MATH* case) or a pair of integers in *MATH*. On the lattice, resources (or targets) are distributed randomly with density *MATH*, hence, on average, there are *MATH* targets. To each target *MATH* is assigned a fixed weight *MATH*, which is a random number uniformly distributed in the interval *MATH*, where *MATH*  is a given parameter. Let *MATH*  denote the set that contains the positions *MATH* and weights *MATH* of the targets.


Foragers. We consider *MATH* walkers with random initial positions on the lattice and that are connected by a complete communication network, namely, every walker is able to communicate with any other group member (see below for cases involving other interaction networks). The time variable *MATH* is discrete. During a time step *MATH*, each walker *MATH* updates its position *MATH* as follows.
1. Self-memory mode: If not on a target, with probability *MATH*  the walker resets to a site that it visited in the past, that is: *MATH* where *MATH* is a random integer uniformly chosen in the interval *MATH*. This implies that the probability of choosing a particular site (a target or not) is proportional to the number of time-steps previously spent on that site. This is the linear preferential revisit scheme mentioned above.
2. Information transfer mode: If not on a target, with probability *MATH* the walker randomly chooses another walker (*MATH*) and relocates to a place already visited by that walker, according to the same preferential rule: *MATH* where *MATH* is a random integer in *MATH*.
3. Random motion mode: If not on a target, with probability *MATH* the walker moves to one of its nearest neighbor sites with equal probability each: *MATH*, where *MATH* in one dimension.
4. Feeding: If on a target (if there exists a *MATH* such that *MATH*), the walker *MATH* stays on that site with probability *MATH*, and with the complementary probability *MATH* uses one of the movement rules *MATH* above with their respective probabilities.


FIGURE 


Hence, in a time step, the walker uses memory with probability *MATH* and takes a random step with probability *MATH*. If the memory mode is chosen, with probability *MATH*, the walker relies on its own experience, and with probability *MATH*, on that of another group member. The parameters *MATH* and *MATH* are critical for learning. Fig.
[1] represents rules (i)-(iv) schematically.
Other interaction networks. We assume that walkers can obtain information from any other group member. This is realistic for those animal societies where there is a high fluidity in association patterns [*REF*]. Still, even these fluid association patterns may be represented by networks with different connectivity [*REF*]. In an arbitrary network, each walker (node *MATH*) has a fixed set of connections to other nodes. In this case, in rule *MATH* one of these nodes (*MATH*) is chosen at random for updating. As a representative example, we will further study the case of random Erd *MATH* s-Renyi (ER) networks, where a connection between any given pair of nodes exists with probability *MATH* (*MATH* corresponding to the complete graph) [*REF*; *REF*]. We also explore the case of random scale-free networks, constructed with the method given in [*REF*], where the number of nodes with *MATH* connections is *MATH*. The power-law exponent *MATH* can take any value *MATH*. Scale-free networks are of interest because they contain highly connected nodes, a property not shared by ER networks. These nodes mimic central individuals, which play important roles in real animal social networks [*REF*; *REF*; *REF*]. Scale-free animal social networks were discussed in [*REF*].
The software specifications and source code with which we obtained most of the results can be found in [*REF*].


FIGURE 


Before proceeding to the results, we recall that the case *MATH* and *MATH* (a single forager and one target of weight *MATH*), studied in [*REF*], exhibits an interesting localization phenomenon. If the rate of memory use *MATH* is non-zero, the walker does not diffuse across the lattice but rather becomes localized for long times in a region centered around the target, independently of its initial position.
Namely, because of the preferential return rule to the previously visited sites and because of the fact that each visit to the target lasts longer than those to any other site, a subtle reinforced learning process emerges where the walker steadily revisits the target site, which becomes the most occupied or &apos;&apos;preferred&quot; site.


FIGURE 


Results


Unless otherwise indicated, the results below are obtained for interactions on the complete graph. In Fig.
[2] we show the walkers&apos; initial and final positions (after *MATH* time steps, with *MATH* large) in four representative numerical simulations. The upper and lower panels correspond to one and two dimensional spaces, and left and right panels are for *MATH* and *MATH*, respectively. In these figures we also display the positions of the targets with the five highest weights *MATH*, among 50 or 100 targets. Notably, for *MATH*, many foragers tend to aggregate around these best targets, creating a much less uniform distribution than initially, especially in *MATH*. In contrast, when *MATH*, the forager distribution remains rather uniform. This preference for occupying a few most profitable targets, among a large set of available sites and targets, can be referred to as selective localization.


Resource selection by the walkers can be quantified through the final occupation probability of each target *MATH* after a long simulation time, when a steady distribution is established: it is denoted as *MATH* and is defined by the probability that a walker chosen at random occupies *MATH*. This quantity is represented against the target weight *MATH* in Figs. (a)-(b), where *MATH* is set to *MATH* (green squares). One observes that *MATH* is very small and practically independent of *MATH* in most of the interval *MATH*, whereas it sharply increases when *MATH* approaches its upper bound *MATH*. In *MATH*, there is a probability as high as *MATH* to be on the target with the highest weight (among the *MATH* targets and *MATH*  total sites available). Our foragers are over-attracted by the most profitable sites and therefore very selective. In contrast, when the foragers do not interact (*MATH*, plots with blue circles), this selectivity practically disappears, despite the fact that the individuals still use their memory at the same rate *MATH*. In this case, each forager localizes around a target close to its initial position.
When the foragers are memory-less random walkers (*MATH*, pink triangles) the selectivity disappears altogether. In this case the foragers are not able to learn. Therefore, the emergence of selective localization here is only possible in connected collectives with memory.


FIGURE 


To investigate how the interacting walkers choose among many targets of different weights, we compare the computed (or perceived) ranking vs.
the real ranking of the targets. The real ranking corresponds to the targets sorted according to their weights *MATH* (the best target has rank *MATH*) and the computed ranking refers to the targets sorted according to their final occupation probability *MATH*. If the group is able to specifically select the best targets, we expect a high correlation between both quantities for the best targets, and lesser correlations as the rank increases. As shown by Figs. (c)-(d), our walkers are not only capable of finding and exploiting these best targets, but overall, they compute the target rank very accurately. In our example, the *MATH* best targets (the first 5 in *MATH* and the first 10 in *MATH*) lie on the diagonal, meaning that these are always correctly identified as such by the group. However, fluctuations are strong for higher ranks. In particular, in *MATH*, poorer targets are sometimes considered as important (occupied frequently), as many points lie under the diagonal.


Figure (a) displays the variations with *MATH* of the final occupation probability *MATH* defined as the probability that a walker chosen at random occupies the best target site (of highest *MATH*). This quantifies here the foraging success of the group. *MATH* presents a maximum for a particular value of *MATH*. In *MATH*, a value of *MATH* is enough for the emerge of collective learning, or *MATH* large. We chose to keep *MATH* in the *MATH* case for consistency and easier comparison. Slightly larger values (*MATH*) lead to even stronger localization in *MATH*. Figure (b) displays *MATH* as a function of the interaction parameter *MATH*. A monotonous increasing behaviour is observed (when *MATH*) and a plateau is reached at about *MATH*. In the following, we choose *MATH*. When memory is suppressed, *MATH* is nearly vanishing for all *MATH*.


These results suggest that many individuals aggregate around the best resource sites. We thus focus on the temporal evolution of the spatial cohesion of the group. To do so, we define the neighborhood of a forager by a segment of length *MATH* with *MATH* in *MATH*, and by a disk of radius *MATH* in *MATH*, centered at the forager position. The length *MATH* represents half of the mean distance between two neighboring foragers if these would be distributed at random in space. For each forager, at time *MATH*, we determine the number of other group members located in its neighborhood, and take the average, denoted as *MATH*, over all foragers and independent simulations. An average over ten different landscape configurations is also performed.
Figure (c) shows *MATH* as function of time in *MATH*. It can be noticed that no aggregation takes place when the walkers are memory-less (*MATH*) or when they have memory but do not interact (*MATH*  and *MATH*): in these cases each walker has, on average, only one neighbor (*MATH*) at all times. In contrast, when the agents have both memory and the ability to transfer information (*MATH* and *MATH*), *MATH* increases with *MATH* and reaches high values, specially in *MATH* (Fig. (c)- Inset). This result, together with the previous findings, indicates that the walkers aggregate around the best targets. Such selective aggregation is an outcome of collective learning and indicates a high foraging success at the group level.
We next investigate the effect of network connectivity among foragers on selective localization. For Erd *MATH* interaction networks, Fig. (d) displays the final *MATH* as a function of the mean number of connections per forager (mean degree), *MATH*, where *MATH* is the connectivity parameter. The final occupation probability of the best target is very low at small *MATH* but rapidly grows and saturates, both in *MATH* and *MATH*. As soon as the walkers have on average 6 or 7 connections, *MATH* has already the same value as for the fully connected graph (*MATH* here). We notice that at *MATH*, the giant component of the network is already well formed, since the percolation threshold occurs at *MATH* in random graphs [*REF*; *REF*].
Therefore, collective learning requires much less connections than in a complete graph, but a network above the percolation threshold is not sufficient either.


Results for random scale-free networks with degree distribution exponent *MATH* (see ref. [*REF*] for details on their construction) are shown in Fig. (e). The final occupation probability of the best target site is maximal for *MATH* (the minimum value of *MATH*  owing to the normalization condition of the degree distribution), where it equals that of the complete graph. *MATH* decreases with *MATH*, i.e. as the graphs become less heterogeneous. Note however that the mean connectivity also decreases with *MATH* in this network model. For *MATH*, the networks are little connected and exhibit weaker localization. Figure (e) shows that the most connected nodes (the &quot;hubs&quot;) are critical for transferring information within the foraging group: the number of walkers that used the knowledge of a node of degree *MATH* to arrive at one of the best target sites for the first time, *MATH*, is a function that increases sharply with *MATH*. Hence, highly connected nodes influence successful decisions of many other nodes.


Discussion


Memoryless random walk processes [*REF*; *REF*; *REF*; *REF*; *REF*; *REF*] in some cases constitute advantageous strategies for searching for resources in unpredictable environments [*REF*]. Stochastic mobility models that incorporate memory are rarely solvable mathematically and their properties are less understood. An exception is the random walk with preferential relocations to places visited in the past, first introduced in [*REF*; *REF*] and later solved in [*REF*; *REF*]. In this model, some displacements are completely random and local in space whereas others are based on memory and preferentially directed to sites that have been occupied often, sometimes far away from the forager&apos;s current position. Recently, we have shown that the trajectories generated by this model, so far studied in homogeneous environments, were actually able to localize specifically around some landscape heterogeneities representing resources [*REF*]. These sites are occupied for a longer time in each visit, compared to other places, and become rapidly reinforced after they have been visited for the first time. Therefore, a form of spatial learning emerges, reminiscent of a foraging animal adapting to its environment.
Here we have studied systems of many agents connected by an information transfer network and following similar movement rules. One of our main results is that a large fraction of group members is able to sharply aggregate around the best resource site in a disordered environment with many resources. In the context considered here, this phenomenon represents a manifestation of collective learning.


A distinctive property of collective learning revealed by the simulations is that individuals that exchange information have a very high probability to occupying the best resource site, among a large set of available resources. In contrast, when the walkers do not communicate, such selective localization does not take place and each walker learns only about its local environment, in the vicinity of the starting position. Therefore, both individual memory and information transfer between group members are necessary for successful group foraging via aggregation around the richest sites.
Aggregation phenomena in populations of diffusive elements similar to the ones studied here have been extensively studied in the context of taxis, where living organisms locally respond to external stimuli by modifying their movement statistics [*REF*]. Large scale aggregation can be beneficial for the survival of starving bacterial colonies, for instance, as it facilitates the location and exploitation of food sources when these are scarce. Aggregation can occur by following diffusive chemicals or slime that individuals leave on their way.
Theoretical models have been analysed mostly in completely homogeneous environments, without sites representing resources [*REF*]. Stable aggregation patterns between the diffusive elements can occur in such cases after a spontaneous symmetry breaking, namely, the densities of population and external signal evolve in time toward non-uniform stationary patterns whose exact locations cannot be predicted exactly, since they depend in a complicated way on the initial density profiles.
In contrast, here we present one of the first studies (to our knowledge) on reinforced random walks in heterogeneous spaces, where translational invariance is broken. Whereas in the processes mentioned above, aggregation and self-localization do not occur at a specific location, in our model the walkers can aggregate in a given environment with a very high probability around the same few specific sites, independently of their starting positions. This property is reminiscent of the behaviour of ant colonies, where a vast majority of individuals is able to select, repeatedly over many experiments, the shorter of two paths separating the nest and a food resource [*REF*]. However, the mechanisms by which collective behaviours emerge in ants are related to chemical trail laying, and they differ from the information transfer processes of the current model, where relocations far beyond the current forager position are allowed. Our study shows that reinforced random walks can be useful for survival in complex environments, where a large number of foraging options exist. The problem studied here can be seen as an extension to spatial contexts of the basic stochastic models of reinforcement learning, where an agent chooses between a set of acts [*REF*; *REF*].


While our model has made the simplifying assumption that resources are always available, in real situations resource patches will be ephemeral, with a highly variable distribution and abundance [*REF*]. This implies that the best available patches, at any given time, will be changing constantly. Our results show that a group of foragers can locate the best available sites by performing reinforced walks and sharing information, but they do not actually find all available resources, or forage in all of them according to their rank. This may also imply that in realistic situations, resource use may not always be optimally efficient [*REF*], especially at the individual level [*REF*]. Competition for resources should also be considered in future modelling, since it represents a cost of information transfer. For example, competition could decrease cohesion and cause the formation of sub-units exploiting a wider range of resource sites [*REF*].
Our model highlights the importance of the topology of the interaction network on the group&apos;s ability for learning collectively. When the interaction network is of Erd *MATH* s-Renyi type, a modest average number of neighbours per individual (six or seven) is sufficient to trigger collective aggregation around the best resource sites.
Further increase in the connectivity does not lead to stronger aggregation/cohesion. This characteristic number of connections is nevertheless significantly larger than the percolation threshold, given by *MATH* neighbour for ER networks [*REF*]. It means that the networks that are efficient for collective learning not only have a giant component but are also densely connected (although not complete), as observed in many primate groups [*REF*]. In spider monkey social networks, in particular, the sum of the association indices of a node (equivalent to its strength) varies between 2 and 7, depending on the individual and year of study [*REF*]. Values around 5 have been reported in other animals, such as dolphins [*REF*] or giraffes [*REF*].


We also found that the presence of highly connected individuals (or &quot;hubs&quot;) in a random, scale-free network is important for collective learning. This is coincident with the results of an empirical study of spider monkeys [*REF*] that found that more central individuals lead collective movements and are followed to available feeding trees that they know about more frequently than non-central individuals.
In flocks of birds, each individual interacts on average with about 6 nearest neighbours independently of the separation distance to these individuals [*REF*; *REF*]. Such topological interactions contribute to the maintenance of robust collective motion and cohesiveness, even in the presence of external perturbations. In flocks, a fixed number of interactions is thought to optimize the trade-off between group cohesion and individual effort [*REF*]. Similarly, in foraging groups, six or seven neighbours may be a good compromise between the benefit of gathering valuable information from others and limited sensory and memory capacities. In an empirical study aimed specifically at uncovering the rules by which spider monkeys share information about feeding trees [*REF*], individuals that know about available feeding trees share this information with an average of 4.25 (*MATH* S.D.) individuals over several detailed observations at feeding trees. More studies are needed on the generality of these minimum numbers of connections, in particular with respect to variations in foraging group size.


Our results allow us to make some predictions for future studies of collective learning in animals. First, groups of animals with the ability to remember the location of resource sites will forage more efficiently when they can exchange information about the location of these sites. This could be tested by manipulating or recording the location of new sites and monitoring the transfer of information between individuals, as in [*REF*]. Second, the number of interaction partners, as well as the configuration of the information transfer network will be important for collective learning to emerge. This could be tested experimentally by manipulating the number of partners each individual has access to, and testing whether the minimum number of connections mentioned above is relevant for real networks.
The memory-based algorithm developed in the present work might find applications in swarm robotics. Experiments in this area can help to better understand collective decision making in nature [*REF*]. In general, a large number of autonomous robots can be designed to coordinate with each other to perform a common task via exchange of information with other robots within a local range. The dynamical rules based on memory studied here require little computation and our results suggest that opinion aggregation could be enhanced thanks to learning processes. The results for 2D disordered environments also suggest that swarms with memory represent a promising tool to solve complex optimization problems in high dimensional spaces.


To summarize, we have presented a model that exhibits collective learning due to the combined use of memory and information transfer between agents. The foraging group as a whole is capable of distinguishing the best resource sites and localize around them. While the specific topology of the network through which they share information seems to not have great impact in these emerging features, it is enough that each walker has, on average, six or seven neighbors (or that there are enough highly connected individuals) for collective learning to appear. This model provides hypotheses and predictions for empirical studies of collective learning, as well as suggesting design principles for search algorithms and pattern recognition.
Acknowledgements: DB acknowledges support from DGAPA-PAPIIT UNAM Grant No. IN105015. AFC thanks A. Aldana for fruitful discussions and Conacyt (Mexico) and PAEP-UNAM for financial support. GRF acknowledges C3-UNAM for logistical support and National Geographic (grant WW008R17) for travel expenses.