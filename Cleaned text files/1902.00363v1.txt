Intelligent architectures for robotics: The merging of cognition and emotion


INTRODUCTION


In the first episode of Westworld, a popular HBO series, a human is examining Dolores, one of the central characters of the show. Dolores speaks with a heavy frontier accent. The human says &quot;lose the accent,&quot; to which she promptly acquiesces. Her answers are charged with emotion, they convey a deep feeling of confusion and anxiety; she&apos;s distraught.
The examiner then commands: &quot;cognition only.&quot; Once again, Dolores does as she&apos;s told, losing all trace of emotion. Dolores is a &quot;host&quot; -- how the humanoid robots are called -- at Westworld, an Old West theme park created for the entertainment of human &quot;guests&quot; who are free to kill or have sex with them.


For over two millennia, Western thinkers have separated emotion from cognition, emotion being the lowly sibling of the two. Cognition helps explain the quantum nature of matter and sends humans to the moon.
Emotion might save the lioness in the savannah but makes humans act irrationally with disconcerting frequency. Against this backdrop, how should autonomous robots be built? Should emotion be part of their information-processing architecture? If so, how should it interact with cognition?


Cognition refers to processes such as memory, attention, language, problem solving, and planning. Many cognitive processes are thought to involve sophisticated functions that might be uniquely human.
Furthermore, they often involve so-called controlled processes, such as when the pursuit of a goal needs to be protected from distraction.
Whereas there is relative agreement about what constitutes cognition, there is less accord about emotion. Some investigators link it to the concepts of drive and motivation, suggesting that emotions are states elicited by rewards and punishers *REF*. Others propose that emotions are involved in the evaluation of events, called &quot;appraisals&quot; *REF*, which can be explicit or implicit. Some approaches focus on basic emotions (for example, fear and anger *REF*) while others focus on an extended set of emotions, including moral ones (for example, pride and envy *REF*). Finally, many researchers suggest that emotions are strongly linked to bodily states *REF*.


In building an &quot;intelligent&quot; robot it might seem best to focus on its cognitive capacities, perhaps disregarding emotion entirely, or perhaps including only as much of emotion as necessary. Fig. 1A illustrates this scenario, where the blue segment represents a cognitive module and the orange segment indicates the emotion module of a hypothetical robot.
When emotion is included, to avoid &quot;emotional interference,&quot; another design property would allow the cognitive module to downregulate emotion inputs, minimizing their influence to the desired extent. Thus, emotion is restricted to contributing to behavior only when deemed useful by the cognitive module.


It is conceivable that the robot in Fig. 1A could function effectively in some settings. The cognitive architecture would endow it with the required problem-solving capabilities, and the emotion module would instantiate a sense of urgency into decisions and actions *REF*. The argument developed here, however, is that this type of architecture, in general, is inherently limited in its behavioral capabilities. For sophisticated intelligent behavior, I argue that cognition and emotion need to be intertwined in the general informationprocessing architecture (Fig. 1B).


Fig. 1. Information-processing architecture of intelligent robots.
(A) Modular architecture with separate cognitive (blue) and emotional (red) components. The cognitive module also inhibits the emotion module when deemed necessary. (B) Non-modular architecture with integrated components. Reproduced with permission *REF*.


What is meant by &quot;sophisticated intelligent behavior?&quot; While the goal here is not to precisely answer this question, the question can be rephrased as follows: &quot;Does building models of emotional/affective mechanisms into our robots make them more natural, more useful, or more efficient?&quot; *REF*. Furthermore, a chief target goal should be autonomy, that is, the ability to function independently in diverse and challenging conditions and environments *REF* (for example, interplanetary travel). Importantly, the argument made here for a cognitive-emotional architecture is not simply rooted in the need for better communication with humans (*REF*; given that the latter do have emotion) or, relatedly, to generate emotional expressions *REF*, or even for survival-related purposes *REF*. The contention is that, for the types of intelligent behaviors frequently described as cognitive (say, attention, problem solving, planning), the integration of emotion and cognition is necessary *REF*.


FIGURE 


To motivate the information-processing architecture described here, I will first describe growing evidence that emotion and cognition are integrated in the brain. Next, general concepts of brain evolution will be reviewed, and implications for the organization of emotion and cognition in the brain discussed. Based on these ideas, a cognitive-emotional architecture will be motivated and proposed properties described. I will then develop the hypothesis that a humanoid robot cannot exhibit fully autonomous &quot;interesting&quot; behaviors without cognitive-emotional integration, which will be summarized via the &quot;Dolores test.&quot; General conclusions will be then outlined.


COGNITION AND EMOTION IN THE BRAIN


How is emotion organized in the brain? Historically, textbooks have described the emotional brain by listing a series of brain regions and discussing their purported main function(s) (see also *REF*). Several subcortical regions would be featured, including the amygdala (&quot;fear processing&quot;), hypothalamus (&quot;survival mechanisms&quot;), periaqueductal gray (&quot;defensive behaviors&quot;), hippocampus (&quot;emotional memory&quot;), nucleus accumbens (&quot;reward processing&quot;), and so on. Cortical regions would include the cingulate cortex (&quot;affective action&quot;), insula (&quot;processing of bodily signals&quot;), and orbitofrontal cortex (&quot;reward processing&quot;).


Although the idea that some brain regions are specialized for emotion is favored by some researchers *REF*, a different view has emerged in the past two decades, one in which emotion and cognition strongly interact and, in fact, are integrated in the brain *REF*. Before describing this perspective, I will first motivate it in intuitive terms.


Consider a hypothetical organism that has its visual cortex (the part that receives signals from the eye&apos;s retina) and its auditory cortex (the part that receives signals from the ear&apos;s cochlea) heavily interconnected with each other. This architecture means that every time signals are processed by the visual cortex, they strongly influence auditory cortex, and vice versa -- vision and audition mutually influence each other. Indeed, it would be better to call the parts of the brain in question visual-auditory (or audio-visual) areas. Even without studying behavior in our hypothetical organism, we could make the strong prediction that it would be unable to respond in a purely visual or auditory way. This is because its brain is built such that the two sensory domains have, in effect, no clear boundary -- they are not independent modules.


Emotion and cognition are not separable in the human brain for similar reasons. Knowledge about anatomy and physiology indicates that the two are closely intertwined *REF*. Next, I describe principles of brain organization that reveal why emotion is not a distinct unit of the brain.


1. Massive Combinatorial Anatomical Connectivity


Computational analysis of anatomical connectivity demonstrates that both cortical and subcortical brain regions are densely interconnected *REF* (Fig. 2). Rich connectivity is not limited to specific sectors of the brain (say, prefrontal cortex) but instead encompasses all of them (including brainstem and cerebellum). Central anatomical properties include: 1) Massive interconnectivity; 2) High global accessibility *REF*; and 3) The existence of a &quot;connectivity core&quot; or &quot;rich-club&quot; of regions marked by especially high levels of connectivity *REF*.
Focusing on macaque cortical regions, one study described a core set of 17 regions spanning parietal, temporal, and frontal cortex that was marked by 92 connectivity density (92 of the connections that could exist were present) *REF*. By combining multiple sources of data, another study described a core that was distributed across all major brain sectors (all cortical lobes, thalamus, and subcortical regions in the forebrain) *REF*.


In all, the anatomical connectivity is such that signals can flow between disparate regions in very few steps. And because hub regions (those that are particularly well connected) aggregate and distribute information widely, diverse types of signals (say, related to perception and action) have the opportunity to influence one another *REF*.


Fig. 2. Large-scale anatomical connectivity. (A) Network analysis of anatomical datasets reveals massive interconnectivity among all sectors of the brain. (B) Illustration of the major lobes of cortex (top) and some of the regions mentioned in the text (bottom). Part (A) reproduced with permission *REF*.


FIGURE 


2. High Distributed Functional Connectivity


Understanding brain function requires characterizing how regions are &quot;functionally connected.&quot; The idea of functional connectivity was devised to characterize how neurons (or regions) interact and was defined as the &quot;temporal coherence&quot; among their activity, for example, as measured by correlating their signals *REF*. Hence, functional connectivity is essentially a description of the joint state of two brain elements, regardless of their anatomical connectivity status (linked by a strong or weak anatomical connection, or even not directly linked at all).


Thus, in general, what is important is not simply a region&apos;s anatomical location, but its position in a space of functional relationships to other regions *REF*. From the perspective of a brain region, at a given time, a region affiliates with a set of other regions, thereby defining a momentary functional circuit. And relatively spared coordinated activity can emerge in brains with substantially altered structural connectivity *REF*. In all, anatomical architectural features support the efficient communication of information even when strong direct structural connections are absent *REF*, and allow functional interactions that vary as a function of context.


It should be pointed out that &quot;functional connectivity&quot; does not distinguish certain scenarios. Consider, for example, two neuronal populations, A and B^1^. Even if A and B are temporally coherent in their activation but only one triggers a causally related consequence in C, the functional connectivity between A and B does not include that information (and some could even question the validity of stating that they are functionally connected). Whereas this is potentially a problem, establishing causation in complex systems is far from straightforward. In fact, the type of Newtonian &quot;billiard ball&quot; causation model at times applied to reasoning about the brain (in this case, A &quot;causes&quot; B much like a billiard ball hitting another) may be in need of a revision *REF*. For example, &quot;probabilistic causation&quot; *REF* or &quot;dynamical systems causation&quot; offer promising avenues. In the latter, the goal is to investigate causation in (possibly non-linear) dynamical systems, and two variables are &quot;causally linked&quot; if they participate in the same dynamical system *REF*.


3. Overlapping and Dynamic Brain Networks


Networks of brain regions collectively support behaviors. Thus, the network itself is the unit, not the brain region. Indeed, research characterizing both anatomical (e.g., *REF*) and functional (e.g., *REF*) networks has grown rapidly in the last decade, and a host of specific networks have been proposed, such as the &quot;salience&quot; (important during the processing of salient events) and &quot;executive&quot; (important during cognitive processes, including attention and working memory) networks *REF*.


At the same time, analysis of anatomical/functional data has repeatedly revealed regions with widespread connectivity (see section above). This implies that describing brain network in terms of disjoint sets of regions (where each brain region belongs to a single network or cluster) only partly captures the complexity of the organization. It is important, therefore, to elucidate the overlapping structure of networks *REF*. In several scientific disciplines, there is increasing realization that actual networks are best understood in terms of overlapping subsystems *REF*. In neuroscience, disjoint networks (that is, non-overlapping) have been favored, although recent investigations have started to study potential ways to characterize overlapping organization *REF*.


In a recent study, we investigated the potential overlapping structure of functional brain connectivity in a data-driven fashion *REF*.
Instead of assuming that regions belong to a single network, we allowed them to belong to all communities (Fig. 3). Thus, when community organization was determined, a node&apos;s participation to every community was estimated; participation strengths were called membership values. Each node was assigned a probability-like membership value to each of the existing communities, resulting in a membership vector with entries between 0 and 1 (and summing to 1); entries close to 1 indicated membership to essentially one community, that is, the non-overlapping case. The approach to detecting overlapping communities we adopted was originally based on the mixed-membership stochastic blocks model *REF*  within the context of stochastic variational inference *REF*. The specific algorithm we employed was developed by Gopalan and Blei *REF*, and can be viewed as a generative Bayesian algorithm favoring assortativity (nodes with similar memberships are more likely to cluster together).


FIGURE 


When applied to resting-state fMRI data, the algorithm captured community organization matching many of the general features of standard disjoint networks. However, the analysis indicated that overlapping communities are not fully captured by a single disjoint community, and that they contain information that is not well described by disjoint communities. To gain a richer understanding of the overlapping networks obtained, for each community, we considered the entire distribution of membership values, that is, we considered the membership values of all brain regions simultaneously. A community containing nodes that affiliated mostly with that community would exhibit a membership distribution with values close to 1. Instead, we found that all mixed communities had many regions with non-trivial membership values far from the peak of 1, which indicated that the overlapping communities were not well described by &quot;exclusive nodes&quot; (nodes that participated in only one community) but by &quot;multi-partner nodes&quot; (nodes that participated in multiple communities).


Furthermore, brain networks are not static but evolve temporally *REF*. Although anatomical pathways change across the life span, faster dynamics are an essential ingredient of functional connections between regions, which vary as a function of context, and are altered by cognitive, emotional, and motivational variables, among others. Therefore, network organization is a dynamic property. Indeed, the growth of methods to characterize time-varying functional connectivity has begun to yield novel characterizations of how network organization evolves *REF*.
In sum, networks are not static and fixed collections of brain regions; they are dynamic coalitions of regions that form and dissolve to meet specific computational needs. This poses several challenges, as the very notion of a network as a coherent unit is undermined. For instance, at what point does a coalition of regions become something other than, say, the salience network? An approach to modeling networks in general that partly mitigates this problem is to conceptualize networks as inherently overlapping. Instead of treating nodes as belonging to a single network, in overlapping networks, each node is a member of every network with a specific probability like membership value, which can then fluctuate across time *REF*.


Dynamic aspects of network function naturally will benefit from understanding interactions in terms of non-linear dynamical systems.
Such systems undergo qualitative changes in behavior (so-called bifurcations) as a function of their input and/or parameter changes. For example, Hansen and colleagues *REF*, show via simulations of a whole-brain mean-field computational model that functional connectivity exhibits rapid transitions between a few discrete states. In the so-called &quot;resting-state&quot; (when participants are not explicitly engaged in a task), such state transitions are spontaneous and often very sharp.


4. Anatomical Connectivity to and from the Body


Emotion is closely linked to bodily states, and the very history of emotion research is defined by the discussion and controversy surrounding the question of the necessity of the body for emotion *REF*.
The exact role of the body in emotion notwithstanding, brain circuits that involve signals to and from the body are important for associated processes.


Brain connectivity affecting the body originates in both cortex and subcortex. In cortex, a notable region is the cingulate cortex *REF*, whose descending projections to autonomic regulatory structures have been amply described (autonomic functions include respiration, heart rate, and pupil response) *REF*. This connectivity is consistent with effects of cingulate electrical stimulation on virtually all autonomic processes, as well as many endocrine mechanisms.
Conversely, visceral pathways carrying signals from the body to the brain reach multiple subcortical and cortical regions. In particular, cortical regions with notable body-related signals include the orbitofrontal cortex, the cingulate gyrus, and the insula *REF*. For example, the physiological condition of the entire body is conveyed to the posterior insular cortex *REF*, which can be considered interceptive cortex, much like parts of parietal cortex are somatosensory cortex, for example. In conclusion, both cortex and subcortex are part of extensive connectional systems that link the body to the brain. In this manner, the entire spectrum of brain signals can affect the body, and vice versa.


5. Merging Cognition and Emotion in the Brain


In summary, anatomical and functional studies reveal that brain regions are massively interconnected. In particular, the brain basis of emotion involves large-scale cortical-subcortical networks that are distributed and sensitive to bodily signals *REF*. The high degree of signal distribution and integration provides a nexus for the intermixing of information related to perception, cognition, emotion, motivation, and action. Importantly, the functional architecture consists of multiple overlapping networks that are highly dynamic and context sensitive.
Thus, how a given brain region affiliates with a specific network shifts as a function of task demands and brain state.


Whereas some regions are more highly interconnected than others, overall information can travel from one part of the brain to another in just a few steps. This implies that the brain&apos;s architecture does not leave much room for isolation of signals; it is promiscuous, with information of a given type being mixed with others. Furthermore, adopting a large-scale network perspective to brain organization helps clarify why some brain structures, such as the amygdala, are thought to be important for emotion: they are important hubs of large-scale connectivity systems. It also illuminates why the impact of emotion is so wide ranging -- for one, it is not possible to impact emotion without affecting cognition.


BRAIN EVOLUTION, COGNITION, AND EMOTION


From an evolutionary perspective, it is sometimes stated that cognition can be considered &quot;the tip of the iceberg,&quot; often associated with &quot;newer&quot; parts of the cortex, while the rest of the iceberg involves emotional processes that rely on &quot;old&quot; subcortical brain regions.
Furthermore, it is presumed that the old emotional system functions in a largely autonomous manner (for discussion, see *REF*).


Some brain system can indeed be considered old. For example, anatomical and behavioral data suggest that ray-finned fishes and land vertebrates probably share an ancestor (&gt;420 million years ago) that already possessed some form of an amygdala *REF* -- a subcortical region that is believed to be particularly important for emotional processing *REF*. And the amygdala of the ancestral amniote (which includes reptiles, birds, and mammals; around 340 million years ago) is believed to have had parts that are key subregions of the human amygdala, for example *REF*.


In the beginning of the twentieth century, neuroanatomists proposed the idea that brain evolution takes place in a fairly progressive fashion, from fishes to amphibians, to reptiles, to birds, and then mammals (culminating with the human brain) -- the idea of progression goes back to Aristotle. In this scheme, the brain evolved via the sequential addition of parts. Thus, in the brain of a cat (a mammal) one could discern older parts that remained largely unchanged underneath the cortex *REF*. Furthermore, it was proposed that structures at the top control the ones at the bottom *REF*. Unfortunately, this erroneous viewpoint *REF* became dominant in neuroscience for many decades. It reached its most dramatic example in Paul MacLean&apos;s proposal of the &quot;triune brain,&quot; which consisted of a reptilian complex (at the base of the brain, including brainstem), to which an &quot;old brain&quot; was added, and later a &quot;new cortex&quot; included in mammals *REF*. In the context of the present review, it is noteworthy that the organization shown in Fig. 1A very much resembles this notion.


It is now known that such framework does not reflect current knowledge of comparative neuroanatomy and does not adequately describe brain evolution (not even in general terms) *REF*. But what is the basic plan of the vertebrate brain? The chassis of the brain of fishes, amphibians, and all other vertebrates contains both subcortex (with multiple parts) and simple forms of cortex (called pallium).


With evolution, brain changes occurred across the brain. But importantly, new circuits originated in a manner that affected both cortex and subcortex.


An example of this type of mutual embedding is provided by the amygdala. In mammals, this structure is composed of a dozen or more subregions. In one study it was found that some amygdala subregions are considerably more &quot;developed&quot; in monkeys than in rats (based on morphological characteristics, such as cell counts and the volume of subregions) *REF*. One possibility is that the observed differences between rats and monkeys are linked to the degree of connectivity of amygdala subregions to other brain structures (for related discussion, see *REF*). In other words, the changes in the amygdala may have paralleled the development of the cortical areas with which these nuclei are interconnected in primates.


Taken together, brain evolution likely proceeded via the mutual embedding of new and old structures, not by the modular addition of parts. Furthermore, separation of &quot;old&quot; and &quot;new&quot; parts does not take into account the extensive anatomical connectivity of brain circuits, as previously discussed, nor the overlapping and dynamic nature of brain networks.


COGNITIVE-EMOTIONAL ARCHITECTURES


With the discussion of the previous two sections in mind, we can return to the central question addressed here: What kind of architecture should an intelligent, autonomous robot have? Although a broad range of cognitive architectures have been proposed *REF*; for review, see *REF*), a general principle is that they are modular (Fig. 4A). For example, they may have low-level modules for action and perception, mid-level modules for task coordination and mid-level perception, and higher levels for task planning and visual cognition, say. Frequently, the top level is connected to a knowledge database. To coordinate the modules, a central controller or supervisor is also posited, which utilizes temporary buffers as part of an active workspace. By and large, the architecture is hierarchical, although parallel components and organization are recognized as important, too *REF*.


In the past two decades, a steady stream of researchers have advocated for the inclusion of emotionrelated components to the general information processing architecture (or &quot;cognitive&quot; architecture, as sometimes it is still referred) *REF*; see contributions in *REF*). One type of argument is that emotion components are needed to instill urgency to action and decisions *REF*. Others have advocated emotion components to aid understand emotion in humans, or to generate human-like expressions (for empathy, say) *REF*. In broad terms, a first-pass effort at including affect entails adding an emotion module so that it can influence other components of the architecture (Fig. 4B).
Another aspect emphasized in the literature is that emotion can be used to generate an internal state that influences actions *REF* (Fig. 3B, right).


FIGURE 


The framework advanced here goes beyond these approaches and proposes that emotion and motivation need to be integrated with all aspects of the architecture. In particular, emotion-related mechanisms influence processing beyond the modulatory aspects of &quot;moods&quot; linked to internal states (hunger, sex-drive, etc.). Of note, in the literature, emotion is often linked to evaluative aspects of the organism-environment relationship and with affective states; motivation is associated with how the organism acts in a given situation (approach vs. withdrawal).
Given the integrationist framework described here, I do not make this distinction *REF*.


As described previously, emotion is not neatly encapsulated in a specific part of the brain -- one cannot point to emotion in the brain.
In addition, cognition was not a late addition to the mammalian, or human, brain *REF*. So, how can we operationalize it in an information-processing architecture? Emotion can be thought of as a set of valuating mechanisms that help organize behavior *REF*, for instance by helping take into account both the costs and benefits linked to percepts and actions *REF*. At a general level, it can be viewed as a biasing mechanism, much like the &quot;cognitive&quot; function of attention.
However, such conceptualization is overly simplistic because emotion does not amount to just providing an extra boost to a specific sensory input, potential plan, or action. When the brain is conceptualized as a complex system of highly interacting networks of regions, we see that emotion is interlocked with perception, cognition, motivation, and action. Whereas we can refer to certain behaviors as &quot;emotional&quot; or &quot;cognitive,&quot; this is only a language short-cut. Thus, the idea of a biasing mechanism is too limited. From a design perspective, all components of the architecture should be influenced by emotional and motivational variables (and vice versa). Thus, the architecture must be strongly non-modular.


To illustrate these ideas, I will describe architectural features inspired by knowledge of brain and behavior. The focus will be on visual perception and executive control, but related schemes can be used in the case of action, too, as adaptive behavior requires monitoring and evaluating the outcome of actions. I will build upon a conceptual framework called the dual competition model which describes how both emotional and motivational signals are integrated with perception and cognition so as to effectively incorporate value into the unfolding of behavior *REF*. The general framework is displayed in Fig. 5A. Because the use of boxes invites a modular interpretation, the architecture is better represented in terms of overlapping networks of processes or mechanisms (Fig. 5B).


1. Perceptual competition


Objects in the environment compete for limited perceptual processing capacity and control of behavior *REF*. Because processing capacity for vision is limited *REF*, selective attention to one part of the visual field comes at the cost of neglecting other parts. Thus, a popular notion is that there is competition for resources in visual cortex *REF*.


FIGURE


In operationalizing competition, we can use the concept of a priority map, which contains representations of spatial locations that are behaviorally important *REF*. Traditionally, &quot;bottom-up&quot; factors (such as stimulus salience) and &quot;top-down&quot; factors (such as goal relevance) were emphasized as the major inputs to determine priority. To these, we must add affective significance (for instance, based on the prior co-occurrence of a stimulus with aversive events) and motivational significance (for instance, based on the prior co-occurrence of a stimulus with rewards) (Fig. 6A) (see also *REF*).
In terms of implementation, the architecture requires mechanisms to embed affective and motivational significance, as well as stimulusand goal-related factors, into perception. This can be accomplished via an explicit priority map (Fig. 6A) or by having multiple influences converge on representations of sensory stimuli (Fig. 6B). In the brain, perceptual competition occurs in part via interactions between regions important for attention (in frontal and parietal cortices, for example) and those that are particularly tuned to the evaluation of affective and motivational significance.


But the above should not be viewed as just an extension of the priority map with just additional variables. In particular, if one considers a predictive coding framework *REF*, internal models of the current input will incorporate features along multiple dimensions, including sensory ones but also affective and motivational significance. Thus, establishing a predictive code involves building internal models that incorporate all of these dimensions simultaneously.


2. Executive control


At the heart of cognition, executive control refers to operations involved in maintaining and updating information, monitoring conflict and/or errors, resisting distracting information, inhibiting prepotent responses, and shifting mental sets. A useful way to conceptualize executive control is in terms of a set of processes, including inhibition, updating, and shifting *REF*. These processes are not independent, however; when a given function is necessitated, resources devoted to one component will not be available to other operations and interference will ensue, possibly compromising performance *REF*.


FIGURE


Dealing with an emotional stimulus or situation requires the types of behavioral adjustments that characterize executive function. For example, updating might be needed to refresh the contents of working memory, shifting might be recruited to switch the current task set, and inhibition might be invoked to cancel previously planned actions.
In this manner, specific resources are coordinated in the service of emotional processing (Fig. 6C) and, if temporarily unavailable to additional task requirements, would compromise performance -- the stronger the emotional manipulation, the stronger the interference (see below). A laboratory example might help illustrate these ideas. Suppose a participant is performing an effortful task of some sort and a change of background color signals that she will receive a mild shock sometime in the next 30 seconds. The participant may update the contents of working memory to include the &quot;shock possible&quot; information. Shifting may occur in that the participant may shift between the execution of the cognitive task and &quot;monitoring for shock&quot; (and possibly preparing for the aversive event) every few seconds. Now, if another cue stimulus indicated that shock would be delivered in the next second, the participant might temporarily inhibit response to the task to prepare for the shock.
Altogether, dealing with the emotional situation necessitates the same types of executive functions considered to be the hallmark of cognition.


Importantly, the intensity of the emotional stimulus (or context) determines if it will improve or hinder behavioral performance. Moderate intensity, in particular, allows resources to be devoted to the situation at hand, improving performance. However, if the intensity is high enough, processes may be temporarily unavailable to handle the aspects of the situation adequately. This inverted-U type of relationship is common in many behavioral settings (Fig. 6D).


THE DOLORES TEST FOR ROBOTICS


Let us consider the humanoid robots of Westworld again. In the scene previously referred to, the central humanoid character, Dolores, was asked to consider and describe her situation by using cognition only.
But could a human &quot;lose all emotion&quot; and describe complex events without a trace of affect like Dolores did? The present framework indicates that the answer to this question is &quot;no.&quot; Unlike Dolores, humans cannot lose all emotion and simply proceed cognitively. The brain is organized such that the mind doesn&apos;t behave in this manner.


Dolores is not human; she is a robot built for the amusement of humans.
Could a sophisticated artificial intelligence be built with separate cognitive and emotional modules? I contend that such a humanoid would be a far cry from the complex hosts of the series, whose behaviors are only possible when emotion and cognition are intertwined. Dolores, for one, would be unable to reflect about her past in a meaningful way just cognitively; emotion is part and parcel of her understanding of the world. And this is not just because she lives in a violent, ruthless world, but because making sense of reality necessitates the integration of emotion and cognition. Could this prediction be tested?


In 1950, Alan Turing *REF* proposed a test to establish the presence of thought in a computer by assessing a machine&apos;s ability to exhibit intelligent behavior indistinguishable from that of a human. In the Turing test, an interrogator is supposed to be in a room separated from a machine and another person. The object of the game is for the interrogator to determine which of the other two is the person and which is the machine. The game is such that the human interrogator is physically separated from the other two. I propose, instead, the Dolores test: one cannot build a humanoid that behaves in a manner as sophisticated as Dolores does that is built with separate emotional and cognitive modules.


A scenario somewhat similar to that envisioned by the Dolores test is featured in the 1982 movie Blade Runner. Humans paid to track down rogue humanoids use the &quot;Voight-Kampff device,&quot; a polygraphlike machine used to help determine whether or not an individual is a robot. The machine measures bodily signals linked to respiration, blush response, heart rate, and eye movement in response to questions dealing with emotion and empathy.


FIGURE 


However, the Dolores test proposed here is fundamentally distinct from the one in Blade Runner. It is not based on the idea that bodily responses to emotionally charged situations would deviate in a detectable way in robots. Instead, it is based on the hypothetical scenario that a robot could be built and that it would display &quot;sophisticated behaviors&quot; of the kind produced by the robots in Westworld. The idea of the test is that, by observing behaviors as the humanoids interact with both other humanoids and humans, humans and humanoids would not be confused with each other if the latter were built according to a modular cognitiveemotional architecture (Fig. 7) -- that is, complex behaviors require a non-modular architecture.


Of course, to make the test sufficiently precise, it would be necessary to operationalize &quot;sophisticated behaviors.&quot; In particular, Turing believed that the question of whether or not machines can think was &quot;too meaningless&quot; to deserve discussion, and therefore sought to formulate the &quot;Imitation Game,&quot; with the interrogator separated from the machine and the other person, as described above.


It has been argued that passing the Turing test does not necessarily show &quot;intelligence.&quot; For example, the Chinese Room argument by Seale *REF* points out that complex rule-based transformations may yield apparent understanding when only mechanical rules are being applied *REF*. Could the behavior required to pass the Dolores test be generated by a set of complex rules? Although a more extended discussion should be taken up elsewhere in the future, the Chinese Room argument itself has fostered intense debate *REF*. For instance, both the &quot;systems reply&quot; and the &quot;virtual machine reply&quot; argue that understanding is not present at the level of rule implementation per se (assuming it would be possible), but at the &quot;systems level&quot; including the rule-implementation mechanisms and (possibly all) other components at play -- thus creating a &quot;virtual&quot; agent that does understand.


CONCLUSIONS


How should intelligent, autonomous robots be built? Information-processing architectures have mostly focused on cognitive components. In the past two decades, emotion components have been increasingly described and advocated as a way to improve human-robot communication, including the understanding of human facial expressions and the generation of expressions to communicate internal states. The survival argument has also been emphasized; emotion can then be used to help prioritize processes and actions that foster continued existence.


The central argument of the present framework is not that emotion is needed -- the answer is a definitive &quot;yes&quot; -- but that emotion and motivation need to be integrated with all information-processing components. This implies that cognitive-emotional integration is a principle of the architecture. Emotion is not an &quot;add on&quot; that endows a robot with &quot;feelings&quot; (for instance, reporting or expressing its internal state). It allows the significance of percepts, plans, and actions to be an integral part of all its computations.


Another implication of the present framework is that the traditional modular engineering approach is inadequate for autonomous robots. What we know about behavior and the brain of mammals (indeed of vertebrates more generally) suggests that an approach heavily influenced by biology is needed. In such framework, centralized control is abdicated, and distributed control is adopted. Cognitive and brain science have struggled with the concept of a homunculus, where &quot;too much&quot; intelligence is relegated to one of its components (but how does that component itself acquire its sophistication?) *REF*.


Information-processing architectures for artificial agents need, likewise, to banish such notions of centralized control (a homunculus).
To return to the scenarios inspired by the Westworld series. Humans cannot &quot;lose all emotion&quot; and continue with their daily lives. I content that sophisticated, autonomous robots will prove the same. They will need cognition and emotion as integrated &quot;components&quot; of their information-processing architecture.