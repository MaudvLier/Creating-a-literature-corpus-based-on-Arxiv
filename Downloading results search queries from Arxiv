import requests
import os
import re

def search_arxiv(query):
    """
    Perform a search on arXiv using the given query.

    Args:
        query (str): The search query.

    Returns:
        list: A list of paper IDs of the search results.
    """
    # Base URL for arXiv API
    base_url = 'http://export.arxiv.org/api/query'

    # Initialize list to store paper IDs
    paper_ids = []

    # Set initial start index for pagination
    start_index = 0

    while True:
        # Construct parameters for the API request
        params = {
            'search_query': query,
            'start': start_index,
            'max_results': 1501  # Maximum number of results per request
        }

        # Send GET request to arXiv API
        response = requests.get(base_url, params=params)

        # Check if request was successful
        if response.status_code == 200:
            # Parse response XML and extract paper IDs
            xml_content = response.text
            current_paper_ids = parse_arxiv_xml(xml_content)

            # Add current batch of paper IDs to the list
            paper_ids.extend(current_paper_ids)

            # Check if there are more results to retrieve
            if len(current_paper_ids) < 1501:
                break  # No more results available
            else:
                # Increment start index for next pagination
                start_index += 1501
        else:
            print(f"Error: Failed to retrieve search results. Status code: {response.status_code}")
            break

    return paper_ids

def parse_arxiv_xml(xml_content):
    """
    Parse the XML content returned by arXiv API and extract paper IDs.

    Args:
        xml_content (str): XML content returned by arXiv API.

    Returns:
        list: A list of paper IDs of the search results.
    """
    # Parse XML using ElementTree
    import xml.etree.ElementTree as ET
    root = ET.fromstring(xml_content)

    # Define namespace for arXiv XML
    namespace = {'arxiv': 'http://www.w3.org/2005/Atom'}

    # Extract paper IDs of search results
    paper_ids = []
    for entry in root.findall('arxiv:entry', namespace):
        paper_id = entry.find('arxiv:id', namespace).text.strip()
        paper_ids.append(paper_id)

    return paper_ids

def extract_terms(query):
    # Extract terms between 'all:' and 'AND'
    terms = re.findall(r'all:([A-Za-z0-9]+)', query)
    return '_'.join(terms)

if __name__ == "__main__":
    # Example search query
    query = 'all:TERM1 AND all:TERM2 AND all:TERM3'

    # Perform search
    paper_ids = search_arxiv(query)

    # Extract terms from the query to create the filename
    terms = extract_terms(query)
    filename = f"paper_ids_{terms}.txt"

    # Specify the folder path where you want to save the text file
    folder_path = "folder\path"

    # Ensure the folder exists
    os.makedirs(folder_path, exist_ok=True)

    # Define the full path for the text file
    file_path = os.path.join(folder_path, filename)

    # Save paper IDs to a text file in the specified folder
    with open(file_path, 'w') as f:
        for paper_id in paper_ids:
            f.write(f"{paper_id}\n")

    print(f"Paper IDs saved to {file_path}.")
